{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"A comprehensive Python framework designed for exploring the loss landscapes of deep learning models."},{"location":"#introduction","title":"Introduction","text":"<p><code>Landscaper</code> is a comprehensive Python framework designed for exploring the loss landscapes of deep learning models. It integrates three key functionalities:</p> <ul> <li>Construction: Builds detailed loss landscape representations through low and high-dimensional sampling, including Hessian analysis adapted from PyHessian.</li> <li>Quantification: Applies advanced metrics, including a novel topological data analysis (TDA) based smoothness metric, enabling new insights into model behavior.</li> <li>Visualization: Offers intuitive tools to visualize and interpret loss landscapes, providing actionable insights beyond traditional performance metrics.</li> </ul> <p>By uniting these aspects, <code>Landscaper</code> empowers users to gain a deeper, more holistic understanding of their model's behavior. More information can be found in the documentation.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Check out the quick start guide for a step-by-step introduction to using <code>Landscaper</code>.</p>"},{"location":"#documentation","title":"Documentation","text":"<p>The full documentation for <code>Landscaper</code> is available at https://vis4sciml.github.io/Landscaper/. It includes detailed instructions on installation, usage, and examples. You can build the docs locally by installing the <code>docs</code> extras and then running <code>mkdocs serve</code>.</p>"},{"location":"#installation","title":"Installation","text":"<p><code>Landscaper</code> is available on PyPI, making it easy to install and integrate into your projects.</p> <p><code>Landscaper</code> requires Python <code>&gt;=3.10,&lt;3.13</code> and PyTorch <code>&gt;=2.0.0</code> and is compatible with both CPU and GPU environments. To install PyTorch, follow the instructions on the PyTorch website to select the appropriate version for your system. Then you can install <code>Landscaper</code> using pip. </p> <p>To install <code>Landscaper</code>, run the following command:</p> <pre><code>pip install landscaper\n</code></pre> <p>To install <code>Landscaper</code> with all the dependencies to run the examples, use:</p> <pre><code>pip install landscaper[examples]\n</code></pre>"},{"location":"#docker","title":"Docker","text":"<p>Additionally, <code>Landscaper</code> provides a Docker image that includes all dependencies, based on the official PyTorch image. You can pull the image from the GitHub Container Registry:</p> <pre><code>docker pull ghcr.io/vis4sciml/landscaper:latest\n</code></pre>"},{"location":"#bibtex-citation","title":"BibTeX Citation","text":"<p>If you use <code>Landscaper</code> in your research, please consider citing it. You can use the following BibTeX entry:</p> <pre><code>@misc{https://doi.org/10.5281/zenodo.15874987,\n  doi = {10.5281/ZENODO.15874987},\n  url = {https://zenodo.org/doi/10.5281/zenodo.15874987},\n  author = {Jiaqing Chen and Nicholas Hadler and Tiankai Xie and Rostyslav Hnatyshyn},\n  title = {Vis4SciML/Landscaper},\n  publisher = {Zenodo},\n  year = {2025},\n  copyright = {Lawrence Berkeley National Labs BSD Variant License}\n}\n</code></pre>"},{"location":"#developers","title":"Developers","text":"<p>Install the dev dependencies with <code>uv sync</code>. When running <code>pytest</code>, pass <code>--html=report.html</code> to be able to visualize images created by the tests.</p>"},{"location":"#copyright","title":"Copyright","text":"<p>Landscaper Copyright (c) 2025, The Regents of the University of California, through Lawrence Berkeley National Laboratory (subject to receipt of any required approvals from the U.S. Dept. of Energy), University of California, Berkeley,  and Arizona State University.  All rights reserved.</p> <p>If you have questions about your rights to use or distribute this software, please contact Berkeley Lab's Intellectual Property Office at IPO@lbl.gov.</p> <p>NOTICE.  This Software was developed under funding from the U.S. Department of Energy and the U.S. Government consequently retains certain rights.  As such, the U.S. Government has been granted for itself and others acting on its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the Software to reproduce, distribute copies to the public, prepare derivative works, and perform publicly and display publicly, and to permit others to do so.</p>"},{"location":"quickstart/","title":"Using Landscaper","text":"<p>Before Landscaper can compute a loss landscape for your model, you will need to define two functions: </p> <ol> <li> <p>A generator function for PyHessian that calculates per-sample gradients for your dataset</p> </li> <li> <p>A function that calculates the loss of your entire dataset. </p> </li> </ol> <p>Leaving these functions as input parameters allows Landscaper to work with a wide range of models with minimal tinkering.</p>"},{"location":"quickstart/#pyhessian","title":"PyHessian","text":"<p>We begin our loss landscape analysis by importing the <code>LossLandscape</code> and <code>PyHessian</code> classes and building a calculator object for the Hessian. </p> <pre><code>from torch import nn, Tensor\nfrom landscaper import LossLandscape, PyHessian\n\nmodel = nn.Sequential(\n    nn.Linear(10, 5),\n    nn.ReLU(),\n    nn.Linear(5, 2)\n)\ncriterion = nn.CrossEntropyLoss()\ndata = Tensor([[0.1]*10, [0.2]*10])  # Example input data\ndevice = 'cpu'  # or 'cuda' if you have a GPU\n\n# Create a Hessian calculator\nhessian_comp = PyHessian(model, criterion, data, device)\n</code></pre> <p>If we look at the definition for the <code>PyHessian</code> class, we can see that there's an additional keyword parameter called <code>hessian_generator</code>. We provide a generic implementation that should work for most <code>PyTorch</code> models, but this can be adjusted to accommodate custom models. If the default implementation doesn't work for your model, try defining a generator function</p> <pre><code>def my_hessian_generator(\n    model: nn.Module,\n    criterion: nn.Module,\n    data: Tensor,\n    device: str\n) -&gt; Generator[Tuple[int, nn.Module]]:\n    \"\"\"\n    A generator function that yields the size of each input sample and its gradient.\n\n    Args:\n        model (nn.Module): The model for which to compute the Hessian.\n        criterion (nn.Module): The loss function, used to compute gradients.\n        data (Tensor): The input data for the model.\n        device (str): The device on which the model is located ('cpu' or 'cuda').\n\n    Yields:\n        Tuple[int, nn.Module]: A tuple containing the size of the input and the gradient of each sample.\n    \"\"\"\n    params = [p for p in model.parameters() if p.requires_grad]\n\n    for sample, target in data: \n        outputs = model.forward(sample)\n        loss = criterion(outputs, targets) \n\n        grads = torch.autograd.grad(\n            loss, params, create_graph=True, materialize_grads=True\n        )\n        yield sample.size(0), grads\n</code></pre> <p>where each iteration yields the size of the input and the gradient of the loss. Most of the time, you will only need to change how the loss is being calculated or how the data is being accessed.</p>"},{"location":"quickstart/#defining-a-scalar-function","title":"Defining a Scalar Function","text":"<p>Once our hessian calculator is set up, we have to define a function that takes a model and our data. This function gets called for every coordinate in the loss landscape with a perturbed version of our model. Here's an example use that calculates the average loss for a model:</p> <pre><code>def scalar_function(model: nn.Module, data: Tensor) -&gt; float:\n    \"\"\"\n    A function that computes the average loss for the model given the data.\n\n    Args:\n        model (nn.Module): The model to compute the loss with.\n        data (Tensor): The input data for the model.\n\n    Returns:\n        float: The average loss for the model.\n    \"\"\"\n    total = 0.0\n    count = 0\n    for d in data:\n        sample, label = d\n        output = model.forward(sample)\n        loss = criterion(output, label)\n        total += loss\n        count += 1\n    return total / count\n</code></pre>"},{"location":"quickstart/#computing-the-loss-landscape","title":"Computing the Loss Landscape","text":"<p>With these elements in place, we can finally call <code>compute</code>:</p> <p><pre><code>directions = hessian_comp.eigenvalues(top_n=3)\n\nlandscape = LossLandscape.compute(\n    model, \n    data,\n    directions,\n    hessian_comp,\n    loss_function,\n    dim=2,\n    device=device\n)\n</code></pre> This will compute the loss landscape for your model using the provided data and hessian calculator. The <code>dim</code> parameter specifies the dimensionality of the perturbation space (2 for 2D landscapes, 3 for 3D landscapes, etc.).</p>"},{"location":"quickstart/#visualizing-the-landscape","title":"Visualizing the Landscape","text":"<p>The landscape can be visualized in a number of different ways once it is finally computed.</p> <pre><code>landscape.show() # shows a 3D render of the landscape if dim=2\nlandscape.show_profile() # shows a 1D landscape profile\nlandscape.show_contour() # contour plot\nlandscape.show_persistence_barcode() # persistence barcode\n</code></pre> <p>If you are interested in examining the merge tree, you can visualize it using networkx: <pre><code>from Landscaper.tda import digraph_mt\nimport networkx as nx\n\nmt = landscape.get_sublevel_tree() # gets the minima merge tree\n# mt = landscape.get_super_tree()\n\ng = digraph_mt(mt)\nnx.draw_planar(g) # draws a planar graph of the merge tree\n</code></pre></p>"},{"location":"notebooks/cnn/","title":"Convolutional Neural Network (CNN)","text":"In\u00a0[1]: Copied! <pre>import torch\nimport torchvision\nimport torchvision.transforms as transforms\n</pre> import torch import torchvision import torchvision.transforms as transforms In\u00a0[2]: Copied! <pre># might have issues with too many files being opened at once, this will prevent that\nimport torch.multiprocessing\ntorch.multiprocessing.set_sharing_strategy('file_system')\n</pre> # might have issues with too many files being opened at once, this will prevent that import torch.multiprocessing torch.multiprocessing.set_sharing_strategy('file_system') In\u00a0[3]: Copied! <pre># Check if CUDA is available\ndevice = \"cpu\"\n</pre> # Check if CUDA is available device = \"cpu\" In\u00a0[4]: Copied! <pre># load in the data\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\nbatch_size = 4\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n</pre> # load in the data transform = transforms.Compose(     [transforms.ToTensor(),      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  batch_size = 4  trainset = torchvision.datasets.CIFAR10(root='./data', train=True,                                         download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,                                           shuffle=True, num_workers=2)  testset = torchvision.datasets.CIFAR10(root='./data', train=False,                                        download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,                                          shuffle=False, num_workers=2)  classes = ('plane', 'car', 'bird', 'cat',            'deer', 'dog', 'frog', 'horse', 'ship', 'truck') In\u00a0[5]: Copied! <pre># setup the model\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = torch.flatten(x, 1) # flatten all dimensions except batch\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nnet = Net()\n</pre> # setup the model import torch.nn as nn import torch.nn.functional as F   class Net(nn.Module):     def __init__(self):         super().__init__()         self.conv1 = nn.Conv2d(3, 6, 5)         self.pool = nn.MaxPool2d(2, 2)         self.conv2 = nn.Conv2d(6, 16, 5)         self.fc1 = nn.Linear(16 * 5 * 5, 120)         self.fc2 = nn.Linear(120, 84)         self.fc3 = nn.Linear(84, 10)      def forward(self, x):         x = self.pool(F.relu(self.conv1(x)))         x = self.pool(F.relu(self.conv2(x)))         x = torch.flatten(x, 1) # flatten all dimensions except batch         x = F.relu(self.fc1(x))         x = F.relu(self.fc2(x))         x = self.fc3(x)         return x   net = Net()  In\u00a0[6]: Copied! <pre>import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n</pre> import torch.optim as optim  criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) In\u00a0[7]: Copied! <pre>for epoch in range(2):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n            running_loss = 0.0\n\nprint('Finished Training')\n</pre> for epoch in range(2):  # loop over the dataset multiple times      running_loss = 0.0     for i, data in enumerate(trainloader, 0):         # get the inputs; data is a list of [inputs, labels]         inputs, labels = data          # zero the parameter gradients         optimizer.zero_grad()          # forward + backward + optimize         outputs = net(inputs)         loss = criterion(outputs, labels)         loss.backward()         optimizer.step()          # print statistics         running_loss += loss.item()         if i % 2000 == 1999:    # print every 2000 mini-batches             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')             running_loss = 0.0  print('Finished Training') <pre>[1,  2000] loss: 2.188\n[1,  4000] loss: 1.905\n[1,  6000] loss: 1.709\n[1,  8000] loss: 1.598\n[1, 10000] loss: 1.535\n[1, 12000] loss: 1.493\n[2,  2000] loss: 1.405\n[2,  4000] loss: 1.395\n[2,  6000] loss: 1.374\n[2,  8000] loss: 1.346\n[2, 10000] loss: 1.319\n[2, 12000] loss: 1.308\nFinished Training\n</pre> In\u00a0[8]: Copied! <pre>PATH = './cifar_net.pth'\n</pre> PATH = './cifar_net.pth' In\u00a0[9]: Copied! <pre>torch.save(net.state_dict(), PATH)\n</pre> torch.save(net.state_dict(), PATH) In\u00a0[10]: Copied! <pre>net = Net()\nnet.load_state_dict(torch.load(PATH, weights_only=True))\n</pre> net = Net() net.load_state_dict(torch.load(PATH, weights_only=True)) Out[10]: <pre>&lt;All keys matched successfully&gt;</pre> In\u00a0[11]: Copied! <pre>trunc_data = []\nfor idx, d in enumerate(trainloader):\n    trunc_data.append(d)    \n    if idx &gt; 20:\n        break\n</pre> trunc_data = [] for idx, d in enumerate(trainloader):     trunc_data.append(d)         if idx &gt; 20:         break In\u00a0[12]: Copied! <pre>from landscaper import LossLandscape, PyHessian\n</pre> from landscaper import LossLandscape, PyHessian In\u00a0[13]: Copied! <pre>hessian_comp = PyHessian(net, criterion, trunc_data, device, try_cache=True)\n</pre> hessian_comp = PyHessian(net, criterion, trunc_data, device, try_cache=True) <pre>Setting model to eval mode. PyHessian will not work with models in training mode!\n</pre> In\u00a0[14]: Copied! <pre>def loss_function(model, data):\n    batch_loss = 0\n    for d in data: \n        tt, lbl_t = d\n        output = model.forward(tt)\n        loss = criterion(output, lbl_t)\n        batch_loss += loss\n    return batch_loss\n</pre> def loss_function(model, data):     batch_loss = 0     for d in data:          tt, lbl_t = d         output = model.forward(tt)         loss = criterion(output, lbl_t)         batch_loss += loss     return batch_loss In\u00a0[15]: Copied! <pre>with torch.backends.cudnn.flags(enabled=False):\n    evals, evecs = hessian_comp.eigenvalues(top_n=3)\n</pre> with torch.backends.cudnn.flags(enabled=False):     evals, evecs = hessian_comp.eigenvalues(top_n=3) <pre>Eigenvectors computed:   0%|     | 0/3 [00:00&lt;?, ?it/s]\nIteration:   0%|               | 0/100 [00:00&lt;?, ?it/s]\nErr: 2419.453932796389:   0%|  | 0/100 [00:00&lt;?, ?it/s]\nErr: 0.3720305878901198:   0%| | 0/100 [00:00&lt;?, ?it/s]\nErr: 0.3720305878901198:   3%| | 3/100 [00:00&lt;00:03, 24\nErr: 0.08530534616737256:   3%| | 3/100 [00:00&lt;00:03, 2\nErr: 0.13727918560462643:   3%| | 3/100 [00:00&lt;00:03, 2\nErr: 0.17578758733191802:   3%| | 3/100 [00:00&lt;00:03, 2\nErr: 0.17578758733191802:   6%| | 6/100 [00:00&lt;00:03, 2\nErr: 0.12598039167350136:   6%| | 6/100 [00:00&lt;00:03, 2\nErr: 0.05714390763312505:   6%| | 6/100 [00:00&lt;00:03, 2\nErr: 0.020702783494086743:   6%| | 6/100 [00:00&lt;00:03, \nErr: 0.020702783494086743:   9%| | 9/100 [00:00&lt;00:03, \nErr: 0.006893269449366529:   9%| | 9/100 [00:00&lt;00:03, \nErr: 0.0022314653772727137:   9%| | 9/100 [00:00&lt;00:03,\nErr: 0.000716336967754484:  11%| | 11/100 [00:00&lt;00:04,\nEigenvectors computed:  33%|\u258e| 1/3 [00:00&lt;00:01,  1.95i\nIteration:   0%|               | 0/100 [00:00&lt;?, ?it/s]\nErr: 1573.9314515401707:   0%| | 0/100 [00:00&lt;?, ?it/s]\nErr: 1.0339873135144184:   0%| | 0/100 [00:00&lt;?, ?it/s]\nErr: 1.0339873135144184:   3%| | 3/100 [00:00&lt;00:03, 27\nErr: 0.23236597280957885:   3%| | 3/100 [00:00&lt;00:03, 2\nErr: 0.07884925645226483:   3%| | 3/100 [00:00&lt;00:03, 2\nErr: 0.03314115118161357:   3%| | 3/100 [00:00&lt;00:03, 2\nErr: 0.03314115118161357:   6%| | 6/100 [00:00&lt;00:03, 2\nErr: 0.02643556082933679:   6%| | 6/100 [00:00&lt;00:03, 2\nErr: 0.02997845626624089:   6%| | 6/100 [00:00&lt;00:03, 2\nErr: 0.034155393936416034:   6%| | 6/100 [00:00&lt;00:03, \nErr: 0.034155393936416034:   9%| | 9/100 [00:00&lt;00:03, \nErr: 0.034948252228067606:   9%| | 9/100 [00:00&lt;00:03, \nErr: 0.03139097033115975:   9%| | 9/100 [00:00&lt;00:03, 2\nErr: 0.024976373385041373:   9%| | 9/100 [00:00&lt;00:03, \nErr: 0.024976373385041373:  12%| | 12/100 [00:00&lt;00:03,\nErr: 0.018018712674257666:  12%| | 12/100 [00:00&lt;00:03,\nErr: 0.012102703638727171:  12%| | 12/100 [00:00&lt;00:03,\nErr: 0.007745459303595756:  12%| | 12/100 [00:00&lt;00:03,\nErr: 0.007745459303595756:  15%|\u258f| 15/100 [00:00&lt;00:03,\nErr: 0.004804816540503904:  15%|\u258f| 15/100 [00:00&lt;00:03,\nErr: 0.0029230282848979237:  15%|\u258f| 15/100 [00:00&lt;00:03\nErr: 0.0017575904576852173:  15%|\u258f| 15/100 [00:00&lt;00:03\nErr: 0.0017575904576852173:  18%|\u258f| 18/100 [00:00&lt;00:03\nErr: 0.0010494091063606855:  18%|\u258f| 18/100 [00:00&lt;00:03\nErr: 0.000623623788815566:  19%|\u258f| 19/100 [00:00&lt;00:03,\nEigenvectors computed:  67%|\u258b| 2/3 [00:01&lt;00:00,  1.36i\nIteration:   0%|               | 0/100 [00:00&lt;?, ?it/s]\nErr: 2077.7263859687578:   0%| | 0/100 [00:00&lt;?, ?it/s]\nErr: 1.2393258941757408:   0%| | 0/100 [00:00&lt;?, ?it/s]\nErr: 1.2393258941757408:   3%| | 3/100 [00:00&lt;00:04, 22\nErr: 0.20227773165601545:   3%| | 3/100 [00:00&lt;00:04, 2\nErr: 0.08732847937513984:   3%| | 3/100 [00:00&lt;00:04, 2\nErr: 0.041852533024182154:   3%| | 3/100 [00:00&lt;00:04, \nErr: 0.041852533024182154:   6%| | 6/100 [00:00&lt;00:04, \nErr: 0.02129136955574801:   6%| | 6/100 [00:00&lt;00:04, 2\nErr: 0.011348380708796254:   6%| | 6/100 [00:00&lt;00:04, \nErr: 0.006236038844525776:   6%| | 6/100 [00:00&lt;00:04, \nErr: 0.006236038844525776:   9%| | 9/100 [00:00&lt;00:03, \nErr: 0.003486384134303802:   9%| | 9/100 [00:00&lt;00:03, \nErr: 0.0019665649473934016:   9%| | 9/100 [00:00&lt;00:03,\nErr: 0.001114348267639015:   9%| | 9/100 [00:00&lt;00:03, \nErr: 0.001114348267639015:  12%| | 12/100 [00:00&lt;00:03,\nErr: 0.0006328513478373731:  12%| | 12/100 [00:00&lt;00:03\nEigenvectors computed: 100%|\u2588| 3/3 [00:01&lt;00:00,  1.55i\n</pre> In\u00a0[16]: Copied! <pre>with torch.backends.cudnn.flags(enabled=False):\n    landscape = LossLandscape.compute(\n    net,\n    trunc_data,\n    evecs,\n    loss_function, # loss function\n    dim=2,\n    distance = 0.01,\n    device=device,\n)\n</pre> with torch.backends.cudnn.flags(enabled=False):     landscape = LossLandscape.compute(     net,     trunc_data,     evecs,     loss_function, # loss function     dim=2,     distance = 0.01,     device=device, ) <pre>Computing 1681 points in 2D space...\n</pre> <pre>Computing 2D landscape: 100%|\u2588| 1681/1681 [00:11&lt;00:00,</pre> <pre>Loss hypercube stats - min: 26.181983947753906, max: 29.56452751159668, mean: 26.91413620240202\n</pre> <pre>\n</pre> In\u00a0[17]: Copied! <pre>landscape.save(\"cnn.npz\")\n</pre> landscape.save(\"cnn.npz\") In\u00a0[18]: Copied! <pre>landscape  = LossLandscape.load_from_npz(\"cnn.npz\")\n</pre> landscape  = LossLandscape.load_from_npz(\"cnn.npz\") In\u00a0[19]: Copied! <pre>landscape.show()\n</pre> landscape.show() <pre>Attempting log-scale surface plot...\n</pre> In\u00a0[20]: Copied! <pre>landscape.show_profile()\n</pre> landscape.show_profile() Out[20]: In\u00a0[21]: Copied! <pre>landscape.show_contour()\n</pre> landscape.show_contour() In\u00a0[22]: Copied! <pre>landscape.show_persistence_barcode()\n</pre> landscape.show_persistence_barcode() In\u00a0[23]: Copied! <pre># we can use this function to convert the merge tree \n# into a networkx graph and visualize it!\nfrom landscaper.tda import digraph_mt\ng = digraph_mt(landscape.get_sublevel_tree())\n</pre> # we can use this function to convert the merge tree  # into a networkx graph and visualize it! from landscaper.tda import digraph_mt g = digraph_mt(landscape.get_sublevel_tree()) In\u00a0[24]: Copied! <pre>import networkx as nx\nnx.draw_planar(g, with_labels=True)\n</pre> import networkx as nx nx.draw_planar(g, with_labels=True) In\u00a0[29]: Copied! <pre>len(g.nodes())\n</pre> len(g.nodes()) Out[29]: <pre>442</pre> In\u00a0[25]: Copied! <pre>landscape.smad()\n</pre> landscape.smad() Out[25]: <pre>0.0</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/cnn/#loss-landscapes-for-cnns","title":"Loss Landscapes for CNNs\u00b6","text":"<p>In this notebook, we show how Landscaper can be used to analyze a CNN trained on the CIFAR-10 dataset. (From https://docs.pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html).</p>"},{"location":"notebooks/cnn/#analyzing-the-loss-landscape","title":"Analyzing the loss landscape\u00b6","text":""},{"location":"notebooks/gnn/","title":"Graph Neural Network (GNN)","text":"In\u00a0[1]: Copied! <pre>import torch\nfrom torch_geometric.datasets import TUDataset\n\ndataset = TUDataset(root=\"data/TUDataset\", name=\"MUTAG\")\n</pre> import torch from torch_geometric.datasets import TUDataset  dataset = TUDataset(root=\"data/TUDataset\", name=\"MUTAG\") In\u00a0[2]: Copied! <pre>torch.manual_seed(12345)\ndataset = dataset.shuffle()\n\ntrain_dataset = dataset[:150]\ntest_dataset = dataset[150:]\n</pre> torch.manual_seed(12345) dataset = dataset.shuffle()  train_dataset = dataset[:150] test_dataset = dataset[150:] In\u00a0[3]: Copied! <pre>from torch_geometric.loader import DataLoader\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n</pre> from torch_geometric.loader import DataLoader  train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False) In\u00a0[4]: Copied! <pre>import torch.nn.functional as F\nfrom torch.nn import Linear\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\n\nclass GCN(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super(GCN, self).__init__()\n        torch.manual_seed(12345)\n        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n        self.lin = Linear(hidden_channels, dataset.num_classes)\n\n    def forward(self, d):\n        x, edge_index, batch = d\n        # 1. Obtain node embeddings\n        x = self.conv1(x, edge_index)\n        x = x.relu()\n        x = self.conv2(x, edge_index)\n        x = x.relu()\n        x = self.conv3(x, edge_index)\n\n        # 2. Readout layer\n        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n\n        # 3. Apply a final classifier\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.lin(x)\n\n        return x\n\n\nmodel = GCN(hidden_channels=64)\n</pre> import torch.nn.functional as F from torch.nn import Linear from torch_geometric.nn import GCNConv, global_mean_pool   class GCN(torch.nn.Module):     def __init__(self, hidden_channels):         super(GCN, self).__init__()         torch.manual_seed(12345)         self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)         self.conv2 = GCNConv(hidden_channels, hidden_channels)         self.conv3 = GCNConv(hidden_channels, hidden_channels)         self.lin = Linear(hidden_channels, dataset.num_classes)      def forward(self, d):         x, edge_index, batch = d         # 1. Obtain node embeddings         x = self.conv1(x, edge_index)         x = x.relu()         x = self.conv2(x, edge_index)         x = x.relu()         x = self.conv3(x, edge_index)          # 2. Readout layer         x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]          # 3. Apply a final classifier         x = F.dropout(x, p=0.5, training=self.training)         x = self.lin(x)          return x   model = GCN(hidden_channels=64) In\u00a0[5]: Copied! <pre>model = GCN(hidden_channels=64)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\ncriterion = torch.nn.CrossEntropyLoss()\n\n\ndef train():\n    model.train()\n\n    for data in train_loader:  # Iterate in batches over the training dataset.\n        out = model((data.x, data.edge_index, data.batch))  # Perform a single forward pass.\n        loss = criterion(out, data.y)  # Compute the loss.\n        loss.backward()  # Derive gradients.\n        optimizer.step()  # Update parameters based on gradients.\n        optimizer.zero_grad()  # Clear gradients.\n\n\ndef test(loader):\n    model.eval()\n\n    correct = 0\n    for data in loader:  # Iterate in batches over the training/test dataset.\n        out = model((data.x, data.edge_index, data.batch))\n        pred = out.argmax(dim=1)  # Use the class with highest probability.\n        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n\n\nfor epoch in range(1, 171):\n    train()\n    train_acc = test(train_loader)\n    test_acc = test(test_loader)\n</pre> model = GCN(hidden_channels=64) optimizer = torch.optim.Adam(model.parameters(), lr=0.01) criterion = torch.nn.CrossEntropyLoss()   def train():     model.train()      for data in train_loader:  # Iterate in batches over the training dataset.         out = model((data.x, data.edge_index, data.batch))  # Perform a single forward pass.         loss = criterion(out, data.y)  # Compute the loss.         loss.backward()  # Derive gradients.         optimizer.step()  # Update parameters based on gradients.         optimizer.zero_grad()  # Clear gradients.   def test(loader):     model.eval()      correct = 0     for data in loader:  # Iterate in batches over the training/test dataset.         out = model((data.x, data.edge_index, data.batch))         pred = out.argmax(dim=1)  # Use the class with highest probability.         correct += int((pred == data.y).sum())  # Check against ground-truth labels.     return correct / len(loader.dataset)  # Derive ratio of correct predictions.   for epoch in range(1, 171):     train()     train_acc = test(train_loader)     test_acc = test(test_loader) In\u00a0[6]: Copied! <pre>PATH = \"./gcn.pth\"\ntorch.save(model.state_dict(), PATH)\n</pre> PATH = \"./gcn.pth\" torch.save(model.state_dict(), PATH) In\u00a0[7]: Copied! <pre>model = GCN(hidden_channels=64)\nmodel.load_state_dict(torch.load(PATH, weights_only=True))\n</pre> model = GCN(hidden_channels=64) model.load_state_dict(torch.load(PATH, weights_only=True)) Out[7]: <pre>&lt;All keys matched successfully&gt;</pre> In\u00a0[8]: Copied! <pre>from landscaper import LossLandscape, PyHessian\n</pre> from landscaper import LossLandscape, PyHessian In\u00a0[9]: Copied! <pre>test_in = []\ntest_lbl = []\nfor data in test_loader:\n    d = (data.x, data.edge_index, data.batch)\n    y = data.y\n    test_in.append(d)\n    test_lbl.append(y)\n    \ndata = list(zip(test_in, test_lbl))\n</pre> test_in = [] test_lbl = [] for data in test_loader:     d = (data.x, data.edge_index, data.batch)     y = data.y     test_in.append(d)     test_lbl.append(y)      data = list(zip(test_in, test_lbl)) In\u00a0[13]: Copied! <pre>from collections.abc import Generator\n\nfrom landscaper.utils import DeviceStr\n\n\ndef gnn_generator(\n    model: torch.nn.Module,\n    criterion: torch.nn.Module,\n    data: torch.utils.data.DataLoader,\n    device: DeviceStr,\n) -&gt; Generator[tuple[int, torch.nn.Module], None, None]:\n    \"\"\"Calculates the per-sample gradient for most PyTorch Geometric models that implement `backward`.\n\n    Args:\n        model (torch.nn.Module): The model to calculate per-sample gradients for.\n        criterion (torch.nn.Module): Function that calculates the loss for the model.\n        data (torch.utils.data.DataLoader): Source of data for the model.\n        device (DeviceStr): Device used for pyTorch calculations.\n\n    Yields:\n        The size of the current input (int) and the model.\n    \"\"\"\n    params = [p for p in model.parameters() if p.requires_grad]\n    for inputs, targets in data:\n        model.zero_grad()  # clear gradients\n        input_size = len(inputs[0])  # assuming inputs is a tuple of (x, edge_index, batch)\n\n        inputs = (inputs[0].to(device), inputs[1].to(device), inputs[2].to(device))  # move inputs to device\n        outputs = model(inputs)\n        loss = criterion(outputs, targets.to(device))\n        grads = torch.autograd.grad(\n            loss, params, create_graph=True, materialize_grads=True\n        )\n        yield input_size, grads\n</pre> from collections.abc import Generator  from landscaper.utils import DeviceStr   def gnn_generator(     model: torch.nn.Module,     criterion: torch.nn.Module,     data: torch.utils.data.DataLoader,     device: DeviceStr, ) -&gt; Generator[tuple[int, torch.nn.Module], None, None]:     \"\"\"Calculates the per-sample gradient for most PyTorch Geometric models that implement `backward`.      Args:         model (torch.nn.Module): The model to calculate per-sample gradients for.         criterion (torch.nn.Module): Function that calculates the loss for the model.         data (torch.utils.data.DataLoader): Source of data for the model.         device (DeviceStr): Device used for pyTorch calculations.      Yields:         The size of the current input (int) and the model.     \"\"\"     params = [p for p in model.parameters() if p.requires_grad]     for inputs, targets in data:         model.zero_grad()  # clear gradients         input_size = len(inputs[0])  # assuming inputs is a tuple of (x, edge_index, batch)          inputs = (inputs[0].to(device), inputs[1].to(device), inputs[2].to(device))  # move inputs to device         outputs = model(inputs)         loss = criterion(outputs, targets.to(device))         grads = torch.autograd.grad(             loss, params, create_graph=True, materialize_grads=True         )         yield input_size, grads In\u00a0[14]: Copied! <pre>hessian_comp = PyHessian(model, criterion, data, \"cpu\", hessian_generator=gnn_generator)\n</pre> hessian_comp = PyHessian(model, criterion, data, \"cpu\", hessian_generator=gnn_generator) In\u00a0[15]: Copied! <pre>evals, evecs = hessian_comp.eigenvalues(top_n=3)\n</pre> evals, evecs = hessian_comp.eigenvalues(top_n=3) <pre>Eigenvectors computed:   0%|                                                             | 0/3 [00:00&lt;?, ?it/s]\nIteration:   0%|                                                                       | 0/100 [00:00&lt;?, ?it/s]\nErr: 2006.044914020932:   0%|                                                          | 0/100 [00:00&lt;?, ?it/s]\nErr: 0.1632026979480903:   0%|                                                         | 0/100 [00:00&lt;?, ?it/s]\nErr: 0.03216761334446554:   0%|                                                        | 0/100 [00:00&lt;?, ?it/s]\nErr: 0.006514429989052389:   0%|                                                       | 0/100 [00:00&lt;?, ?it/s]\nErr: 0.0012813347829023246:   0%|                                                      | 0/100 [00:00&lt;?, ?it/s]\nErr: 0.0002508581697236493:   6%|\u2588\u2588\u258a                                           | 6/100 [00:00&lt;00:01, 86.92it/s]\n\nIteration:   0%|                                                                       | 0/100 [00:00&lt;?, ?it/s]\nErr: 4040.265718091858:   0%|                                                          | 0/100 [00:00&lt;?, ?it/s]\nErr: 0.25920966596855677:   0%|                                                        | 0/100 [00:00&lt;?, ?it/s]\nErr: 0.0015697038778225072:   0%|                                                      | 0/100 [00:00&lt;?, ?it/s]\nErr: 3.9460767631673875e-05:   4%|\u2588\u258a                                           | 4/100 [00:00&lt;00:01, 87.88it/s]\nEigenvectors computed:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                 | 2/3 [00:00&lt;00:00, 16.32it/s]\nIteration:   0%|                                                                       | 0/100 [00:00&lt;?, ?it/s]\nErr: 819.5344064199825:   0%|                                                          | 0/100 [00:00&lt;?, ?it/s]\nErr: 1.1592245534700332:   0%|                                                         | 0/100 [00:00&lt;?, ?it/s]\nErr: 0.10846188736652841:   0%|                                                        | 0/100 [00:00&lt;?, ?it/s]\nErr: 0.01754467557081164:   0%|                                                        | 0/100 [00:00&lt;?, ?it/s]\nErr: 0.004497386254928624:   0%|                                                       | 0/100 [00:00&lt;?, ?it/s]\nErr: 0.001650250179655629:   0%|                                                       | 0/100 [00:00&lt;?, ?it/s]\nErr: 0.0007207597819777925:   7%|\u2588\u2588\u2588\u258f                                          | 7/100 [00:00&lt;00:00, 99.52it/s]\nEigenvectors computed: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 15.20it/s]\n</pre> In\u00a0[17]: Copied! <pre>def loss_function(mdl, data):\n    batch_loss = 0\n    for d in data:\n        tt, lbl_t = d\n        output = model.forward(tt)\n        loss = criterion(output, lbl_t)\n        batch_loss += loss\n    return batch_loss\n</pre> def loss_function(mdl, data):     batch_loss = 0     for d in data:         tt, lbl_t = d         output = model.forward(tt)         loss = criterion(output, lbl_t)         batch_loss += loss     return batch_loss In\u00a0[18]: Copied! <pre>with torch.backends.cudnn.flags(enabled=False):\n    landscape = LossLandscape.compute(\n        model,\n        data,\n        evecs,\n        loss_function,  # loss function\n        dim=2,\n        distance=0.01,\n        device=\"cpu\",\n    )\n</pre> with torch.backends.cudnn.flags(enabled=False):     landscape = LossLandscape.compute(         model,         data,         evecs,         loss_function,  # loss function         dim=2,         distance=0.01,         device=\"cpu\",     ) <pre>Computing 1681 points in 2D space...\n</pre> <pre>Computing 2D landscape: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1681/1681 [00:03&lt;00:00, 441.97it/s]</pre> <pre>Loss hypercube stats - min: 0.5090966820716858, max: 0.5779156684875488, mean: 0.524149081807701\n</pre> <pre>\n</pre> In\u00a0[19]: Copied! <pre>landscape.save(\"gnn.npz\")\n</pre> landscape.save(\"gnn.npz\") In\u00a0[20]: Copied! <pre>landscape = LossLandscape.load_from_npz(\"gnn.npz\")\n</pre> landscape = LossLandscape.load_from_npz(\"gnn.npz\") In\u00a0[21]: Copied! <pre>landscape.show()\n</pre> landscape.show() <pre>Attempting log-scale surface plot...\n</pre> In\u00a0[22]: Copied! <pre>landscape.show_profile()\n</pre> landscape.show_profile() Out[22]: In\u00a0[23]: Copied! <pre>landscape.show_contour()\n</pre> landscape.show_contour() In\u00a0[24]: Copied! <pre>landscape.show_persistence_barcode()\n</pre> landscape.show_persistence_barcode() In\u00a0[25]: Copied! <pre># we can use this function to convert the merge tree\n# into a networkx graph and visualize it!\nfrom landscaper.tda import merge_tree_to_nx\n\ng = merge_tree_to_nx(landscape.get_sublevel_tree())\n</pre> # we can use this function to convert the merge tree # into a networkx graph and visualize it! from landscaper.tda import merge_tree_to_nx  g = merge_tree_to_nx(landscape.get_sublevel_tree()) In\u00a0[26]: Copied! <pre>import networkx as nx\n\nnx.draw_planar(g, with_labels=True)\n</pre> import networkx as nx  nx.draw_planar(g, with_labels=True) In\u00a0[27]: Copied! <pre>landscape.smad()\n</pre> landscape.smad() Out[27]: <pre>0.0</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/gnn/#graph-classification-with-graph-neural-networks","title":"Graph Classification with Graph Neural Networks\u00b6","text":"<p>From (https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=N-FO5xL3mw98)</p> <p>In this tutorial session we will have a closer look at how to apply Graph Neural Networks (GNNs) to the task of graph classification. Graph classification refers to the problem of classifiying entire graphs (in contrast to nodes), given a dataset of graphs, based on some structural graph properties. Here, we want to embed entire graphs, and we want to embed those graphs in such a way so that they are linearly separable given a task at hand. We will train the model and then analyze its loss landscape after.</p>"},{"location":"notebooks/gnn/#generate-loss-landscape","title":"Generate loss landscape\u00b6","text":""},{"location":"notebooks/rnn/","title":"Recurrent Neural Network (RNN)","text":"<p>This notebook demonstrates how you can use PyLossLandscapes to compute a loss landscape and save the resulting data to be analyzed later. We will use an RNN to classify names by their ethnic origin (from https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html).</p> In\u00a0[1]: Copied! <pre># first we have to download the dataset\nimport urllib.request\nimport subprocess\nurllib.request.urlretrieve(\"https://download.pytorch.org/tutorial/data.zip\", \"data.zip\")\n</pre> # first we have to download the dataset import urllib.request import subprocess urllib.request.urlretrieve(\"https://download.pytorch.org/tutorial/data.zip\", \"data.zip\") Out[1]: <pre>('data.zip', &lt;http.client.HTTPMessage at 0x7ff234583280&gt;)</pre> In\u00a0[2]: Copied! <pre># unzip the archive\nsubprocess.run([\"unzip\", \"data.zip\"])\n</pre> # unzip the archive subprocess.run([\"unzip\", \"data.zip\"]) <pre>Archive:  data.zip\n</pre> <pre>replace data/eng-fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n(EOF or read error, treating as \"[N]one\" ...)\n</pre> Out[2]: <pre>CompletedProcess(args=['unzip', 'data.zip'], returncode=1)</pre> In\u00a0[3]: Copied! <pre>import torch\n\n# Check if CUDA is available\ndevice = torch.device('cpu')\nif torch.cuda.is_available():\n    device = torch.device('cuda')\n\ntorch.set_default_device(device)\nprint(f\"Using device = {torch.get_default_device()}\")\n</pre> import torch  # Check if CUDA is available device = torch.device('cpu') if torch.cuda.is_available():     device = torch.device('cuda')  torch.set_default_device(device) print(f\"Using device = {torch.get_default_device()}\") <pre>Using device = cuda:0\n</pre> In\u00a0[4]: Copied! <pre>import string\nimport unicodedata\n\n# We can use \"_\" to represent an out-of-vocabulary character, that is, any character we are not handling in our model\nallowed_characters = string.ascii_letters + \" .,;'\" + \"_\"\nn_letters = len(allowed_characters)\n\n# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n        and c in allowed_characters\n    )\n</pre> import string import unicodedata  # We can use \"_\" to represent an out-of-vocabulary character, that is, any character we are not handling in our model allowed_characters = string.ascii_letters + \" .,;'\" + \"_\" n_letters = len(allowed_characters)  # Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427 def unicodeToAscii(s):     return ''.join(         c for c in unicodedata.normalize('NFD', s)         if unicodedata.category(c) != 'Mn'         and c in allowed_characters     ) In\u00a0[5]: Copied! <pre># Find letter index from all_letters, e.g. \"a\" = 0\ndef letterToIndex(letter):\n    # return our out-of-vocabulary character if we encounter a letter unknown to our model\n    if letter not in allowed_characters:\n        return allowed_characters.find(\"_\")\n    else:\n        return allowed_characters.find(letter)\n\n# Turn a line into a &lt;line_length x 1 x n_letters&gt;,\n# or an array of one-hot letter vectors\ndef lineToTensor(line):\n    tensor = torch.zeros(len(line), 1, n_letters)\n    for li, letter in enumerate(line):\n        tensor[li][0][letterToIndex(letter)] = 1\n    return tensor\n</pre> # Find letter index from all_letters, e.g. \"a\" = 0 def letterToIndex(letter):     # return our out-of-vocabulary character if we encounter a letter unknown to our model     if letter not in allowed_characters:         return allowed_characters.find(\"_\")     else:         return allowed_characters.find(letter)  # Turn a line into a , # or an array of one-hot letter vectors def lineToTensor(line):     tensor = torch.zeros(len(line), 1, n_letters)     for li, letter in enumerate(line):         tensor[li][0][letterToIndex(letter)] = 1     return tensor In\u00a0[6]: Copied! <pre>from io import open\nimport glob\nimport os\nimport time\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass NamesDataset(Dataset):\n\n    def __init__(self, data_dir):\n        self.data_dir = data_dir #for provenance of the dataset\n        self.load_time = time.localtime #for provenance of the dataset\n        labels_set = set() #set of all classes\n\n        self.data = []\n        self.data_tensors = []\n        self.labels = []\n        self.labels_tensors = []\n\n        #read all the ``.txt`` files in the specified directory\n        text_files = glob.glob(os.path.join(data_dir, '*.txt'))\n        for filename in text_files:\n            label = os.path.splitext(os.path.basename(filename))[0]\n            labels_set.add(label)\n            lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n            for name in lines:\n                self.data.append(name)\n                self.data_tensors.append(lineToTensor(name))\n                self.labels.append(label)\n\n        #Cache the tensor representation of the labels\n        self.labels_uniq = list(labels_set)\n        for idx in range(len(self.labels)):\n            temp_tensor = torch.tensor([self.labels_uniq.index(self.labels[idx])], dtype=torch.long)\n            self.labels_tensors.append(temp_tensor)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        data_item = self.data[idx]\n        data_label = self.labels[idx]\n        data_tensor = self.data_tensors[idx]\n        label_tensor = self.labels_tensors[idx]\n\n        return label_tensor, data_tensor, data_label, data_item\n</pre> from io import open import glob import os import time  import torch from torch.utils.data import Dataset, DataLoader  class NamesDataset(Dataset):      def __init__(self, data_dir):         self.data_dir = data_dir #for provenance of the dataset         self.load_time = time.localtime #for provenance of the dataset         labels_set = set() #set of all classes          self.data = []         self.data_tensors = []         self.labels = []         self.labels_tensors = []          #read all the ``.txt`` files in the specified directory         text_files = glob.glob(os.path.join(data_dir, '*.txt'))         for filename in text_files:             label = os.path.splitext(os.path.basename(filename))[0]             labels_set.add(label)             lines = open(filename, encoding='utf-8').read().strip().split('\\n')             for name in lines:                 self.data.append(name)                 self.data_tensors.append(lineToTensor(name))                 self.labels.append(label)          #Cache the tensor representation of the labels         self.labels_uniq = list(labels_set)         for idx in range(len(self.labels)):             temp_tensor = torch.tensor([self.labels_uniq.index(self.labels[idx])], dtype=torch.long)             self.labels_tensors.append(temp_tensor)      def __len__(self):         return len(self.data)      def __getitem__(self, idx):         data_item = self.data[idx]         data_label = self.labels[idx]         data_tensor = self.data_tensors[idx]         label_tensor = self.labels_tensors[idx]          return label_tensor, data_tensor, data_label, data_item In\u00a0[7]: Copied! <pre>alldata = NamesDataset(\"data/names\")\n#dataloader = DataLoader(alldata, batch_size=64, shuffle=False, num_workers=1, generator=torch.Generator(device='cuda'))\n</pre> alldata = NamesDataset(\"data/names\") #dataloader = DataLoader(alldata, batch_size=64, shuffle=False, num_workers=1, generator=torch.Generator(device='cuda')) In\u00a0[8]: Copied! <pre>train_set, test_set = torch.utils.data.random_split(alldata, [.85, .15], generator=torch.Generator(device=device).manual_seed(2024))\n</pre> train_set, test_set = torch.utils.data.random_split(alldata, [.85, .15], generator=torch.Generator(device=device).manual_seed(2024)) In\u00a0[9]: Copied! <pre>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass CharRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(CharRNN, self).__init__()\n\n        self.rnn = nn.RNN(input_size, hidden_size)\n        self.h2o = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, line_tensor):\n        rnn_out, hidden = self.rnn(line_tensor)\n        output = self.h2o(hidden[0])\n        output = self.softmax(output)\n\n        return output\n</pre> import torch.nn as nn import torch.nn.functional as F  class CharRNN(nn.Module):     def __init__(self, input_size, hidden_size, output_size):         super(CharRNN, self).__init__()          self.rnn = nn.RNN(input_size, hidden_size)         self.h2o = nn.Linear(hidden_size, output_size)         self.softmax = nn.LogSoftmax(dim=1)      def forward(self, line_tensor):         rnn_out, hidden = self.rnn(line_tensor)         output = self.h2o(hidden[0])         output = self.softmax(output)          return output In\u00a0[10]: Copied! <pre>n_hidden = 128\nrnn = CharRNN(n_letters, n_hidden, len(alldata.labels_uniq))\n</pre> n_hidden = 128 rnn = CharRNN(n_letters, n_hidden, len(alldata.labels_uniq)) In\u00a0[11]: Copied! <pre>def label_from_output(output, output_labels):\n    top_n, top_i = output.topk(1)\n    label_i = top_i[0].item()\n    return output_labels[label_i], label_i\n</pre> def label_from_output(output, output_labels):     top_n, top_i = output.topk(1)     label_i = top_i[0].item()     return output_labels[label_i], label_i In\u00a0[12]: Copied! <pre>def get_params_grad(model):\n    \"\"\"\n    get model parameters and corresponding gradients\n    \"\"\"\n    params = []\n    grads = []\n    for param in model.parameters():\n        if not param.requires_grad:\n            continue\n        params.append(param)\n        grads.append(torch.tensor(0.0) if param.grad is None else param.grad + 0.)\n    return params, grads\n</pre> def get_params_grad(model):     \"\"\"     get model parameters and corresponding gradients     \"\"\"     params = []     grads = []     for param in model.parameters():         if not param.requires_grad:             continue         params.append(param)         grads.append(torch.tensor(0.0) if param.grad is None else param.grad + 0.)     return params, grads In\u00a0[13]: Copied! <pre>import random\nimport numpy as np\n\ndef train(rnn, training_data, n_epoch = 10, n_batch_size = 64, report_every = 50, learning_rate = 0.2, criterion = nn.NLLLoss()):\n    \"\"\"\n    Learn on a batch of training_data for a specified number of iterations and reporting thresholds\n    \"\"\"\n    # Keep track of losses for plotting\n    current_loss = 0\n    all_losses = []\n    rnn.train()\n    optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n\n    start = time.time()\n    print(f\"training on data set with n = {len(training_data)}\")\n\n    for iter in range(1, n_epoch + 1):\n        rnn.zero_grad() # clear the gradients\n\n        # create some minibatches\n        # we cannot use dataloaders because each of our names is a different length\n        batches = list(range(len(training_data)))\n        random.shuffle(batches)\n        batches = np.array_split(batches, len(batches) //n_batch_size )\n\n        for idx, batch in enumerate(batches):\n            batch_loss = 0\n            for i in batch: #for each example in this batch\n                (label_tensor, text_tensor, label, text) = training_data[i]\n                text_tensor = lineToTensor(text)\n                output = rnn.forward(text_tensor)\n                loss = criterion(output, label_tensor)\n                batch_loss += loss\n\n            # optimize parameters\n            batch_loss.backward()\n            nn.utils.clip_grad_norm_(rnn.parameters(), 3)\n            optimizer.step()\n            optimizer.zero_grad()\n\n            current_loss += batch_loss.item() / len(batch)\n\n        all_losses.append(current_loss / len(batches) )\n        if iter % report_every == 0:\n            print(f\"{iter} ({iter / n_epoch:.0%}): \\t average batch loss = {all_losses[-1]}\")\n        current_loss = 0\n\n    return all_losses\n</pre> import random import numpy as np  def train(rnn, training_data, n_epoch = 10, n_batch_size = 64, report_every = 50, learning_rate = 0.2, criterion = nn.NLLLoss()):     \"\"\"     Learn on a batch of training_data for a specified number of iterations and reporting thresholds     \"\"\"     # Keep track of losses for plotting     current_loss = 0     all_losses = []     rnn.train()     optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)      start = time.time()     print(f\"training on data set with n = {len(training_data)}\")      for iter in range(1, n_epoch + 1):         rnn.zero_grad() # clear the gradients          # create some minibatches         # we cannot use dataloaders because each of our names is a different length         batches = list(range(len(training_data)))         random.shuffle(batches)         batches = np.array_split(batches, len(batches) //n_batch_size )          for idx, batch in enumerate(batches):             batch_loss = 0             for i in batch: #for each example in this batch                 (label_tensor, text_tensor, label, text) = training_data[i]                 text_tensor = lineToTensor(text)                 output = rnn.forward(text_tensor)                 loss = criterion(output, label_tensor)                 batch_loss += loss              # optimize parameters             batch_loss.backward()             nn.utils.clip_grad_norm_(rnn.parameters(), 3)             optimizer.step()             optimizer.zero_grad()              current_loss += batch_loss.item() / len(batch)          all_losses.append(current_loss / len(batches) )         if iter % report_every == 0:             print(f\"{iter} ({iter / n_epoch:.0%}): \\t average batch loss = {all_losses[-1]}\")         current_loss = 0      return all_losses In\u00a0[14]: Copied! <pre>#all_losses = train(rnn, train_set, n_epoch=27, learning_rate=0.15, report_every=5)\n</pre> #all_losses = train(rnn, train_set, n_epoch=27, learning_rate=0.15, report_every=5) In\u00a0[15]: Copied! <pre># save the model\n#torch.save(rnn.state_dict(), 'model.pth')\n</pre> # save the model #torch.save(rnn.state_dict(), 'model.pth') In\u00a0[16]: Copied! <pre>rnn = CharRNN(n_letters, n_hidden, len(alldata.labels_uniq))\nrnn.load_state_dict(torch.load('model.pth'))\n</pre> rnn = CharRNN(n_letters, n_hidden, len(alldata.labels_uniq)) rnn.load_state_dict(torch.load('model.pth')) Out[16]: <pre>&lt;All keys matched successfully&gt;</pre> In\u00a0[17]: Copied! <pre>from landscaper import LossLandscape, PyHessian\n</pre> from landscaper import LossLandscape, PyHessian In\u00a0[18]: Copied! <pre>data = [(dt, lbl_t) for (lbl_t, dt, dl, di) in train_set][:50]\n</pre> data = [(dt, lbl_t) for (lbl_t, dt, dl, di) in train_set][:50] In\u00a0[19]: Copied! <pre># create a hessian calculator based on our model\nwith torch.backends.cudnn.flags(enabled=False):\n    hessian_comp = PyHessian(rnn, nn.NLLLoss(), data, device, try_cache=True)\n</pre> # create a hessian calculator based on our model with torch.backends.cudnn.flags(enabled=False):     hessian_comp = PyHessian(rnn, nn.NLLLoss(), data, device, try_cache=True) <pre>Setting model to eval mode. PyHessian will not work with models in training mode!\n</pre> In\u00a0[20]: Copied! <pre># for the loss landscape computation to work, we need to define how the loss should be calculated\nlfn = nn.NLLLoss()\ndef loss_function(model, data):\n    batch_loss = 0\n    for d in data: \n        tt, lbl_t = d\n        output = rnn.forward(tt)\n        loss = lfn(output, lbl_t)\n        batch_loss += loss\n    return batch_loss / len(data)\n</pre> # for the loss landscape computation to work, we need to define how the loss should be calculated lfn = nn.NLLLoss() def loss_function(model, data):     batch_loss = 0     for d in data:          tt, lbl_t = d         output = rnn.forward(tt)         loss = lfn(output, lbl_t)         batch_loss += loss     return batch_loss / len(data) In\u00a0[21]: Copied! <pre>with torch.backends.cudnn.flags(enabled=False):\n    evals, evecs = hessian_comp.eigenvalues(top_n=3, maxIter=100)\n</pre> with torch.backends.cudnn.flags(enabled=False):     evals, evecs = hessian_comp.eigenvalues(top_n=3, maxIter=100) <pre>Eigenvectors computed:   0%|                                    | 0/3 [00:00&lt;?, ?it/s]\nIteration:   0%|                                              | 0/100 [00:00&lt;?, ?it/s]\nIteration:   1%|\u258d                                     | 1/100 [00:00&lt;00:31,  3.09it/s]\nSpectral gap: 1697.8530524356609:   1%|\u258f              | 1/100 [00:00&lt;00:31,  3.09it/s]\nSpectral gap: 1697.8530524356609:   2%|\u258e              | 2/100 [00:00&lt;00:20,  4.75it/s]\nSpectral gap: 4.0317867166203465:   2%|\u258e              | 2/100 [00:00&lt;00:20,  4.75it/s]\nSpectral gap: 4.0317867166203465:   3%|\u258d              | 3/100 [00:00&lt;00:16,  5.71it/s]\nSpectral gap: 0.24763802237362204:   3%|\u258d             | 3/100 [00:00&lt;00:16,  5.71it/s]\nSpectral gap: 0.24763802237362204:   4%|\u258c             | 4/100 [00:00&lt;00:15,  6.34it/s]\nSpectral gap: 0.03862144724807775:   4%|\u258c             | 4/100 [00:00&lt;00:15,  6.34it/s]\nSpectral gap: 0.03862144724807775:   5%|\u258b             | 5/100 [00:00&lt;00:14,  6.73it/s]\nSpectral gap: 0.009471561228870908:   5%|\u258b            | 5/100 [00:00&lt;00:14,  6.73it/s]\nSpectral gap: 0.009471561228870908:   6%|\u258a            | 6/100 [00:00&lt;00:13,  6.97it/s]\nSpectral gap: 0.002809408647258704:   6%|\u258a            | 6/100 [00:01&lt;00:13,  6.97it/s]\nSpectral gap: 0.002809408647258704:   7%|\u2589            | 7/100 [00:01&lt;00:13,  7.12it/s]\nSpectral gap: 0.000890555740272384:   7%|\u2589            | 7/100 [00:01&lt;00:13,  7.12it/s]\nEigenvectors computed:  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                  | 1/3 [00:01&lt;00:02,  1.27s/it]\nIteration:   0%|                                              | 0/100 [00:00&lt;?, ?it/s]\nIteration:   1%|\u258d                                     | 1/100 [00:00&lt;00:13,  7.46it/s]\nSpectral gap: 39.31103214689547:   1%|\u258f               | 1/100 [00:00&lt;00:13,  7.46it/s]\nSpectral gap: 39.31103214689547:   2%|\u258e               | 2/100 [00:00&lt;00:13,  7.47it/s]\nSpectral gap: 14.286212563922914:   2%|\u258e              | 2/100 [00:00&lt;00:13,  7.47it/s]\nSpectral gap: 14.286212563922914:   3%|\u258d              | 3/100 [00:00&lt;00:12,  7.60it/s]\nSpectral gap: 1.2850148610548655:   3%|\u258d              | 3/100 [00:00&lt;00:12,  7.60it/s]\nSpectral gap: 1.2850148610548655:   4%|\u258c              | 4/100 [00:00&lt;00:12,  7.65it/s]\nSpectral gap: 0.46345546155986367:   4%|\u258c             | 4/100 [00:00&lt;00:12,  7.65it/s]\nSpectral gap: 0.46345546155986367:   5%|\u258b             | 5/100 [00:00&lt;00:12,  7.68it/s]\nSpectral gap: 0.28869205862514735:   5%|\u258b             | 5/100 [00:00&lt;00:12,  7.68it/s]\nSpectral gap: 0.28869205862514735:   6%|\u258a             | 6/100 [00:00&lt;00:12,  7.68it/s]\nSpectral gap: 0.2058390318749211:   6%|\u2589              | 6/100 [00:00&lt;00:12,  7.68it/s]\nSpectral gap: 0.2058390318749211:   7%|\u2588              | 7/100 [00:00&lt;00:12,  7.70it/s]\nSpectral gap: 0.13864459134254078:   7%|\u2589             | 7/100 [00:01&lt;00:12,  7.70it/s]\nSpectral gap: 0.13864459134254078:   8%|\u2588             | 8/100 [00:01&lt;00:13,  6.90it/s]\nSpectral gap: 0.08120663668496621:   8%|\u2588             | 8/100 [00:01&lt;00:13,  6.90it/s]\nSpectral gap: 0.08120663668496621:   9%|\u2588\u258e            | 9/100 [00:01&lt;00:16,  5.54it/s]\nSpectral gap: 0.03516392243545905:   9%|\u2588\u258e            | 9/100 [00:01&lt;00:16,  5.54it/s]\nSpectral gap: 0.03516392243545905:  10%|\u2588\u258e           | 10/100 [00:01&lt;00:18,  4.84it/s]\nSpectral gap: 0.0010554006469288759:  10%|\u2588          | 10/100 [00:01&lt;00:18,  4.84it/s]\nSpectral gap: 0.0010554006469288759:  11%|\u2588\u258f         | 11/100 [00:01&lt;00:19,  4.46it/s]\nSpectral gap: 0.030771533773091123:  11%|\u2588\u258e          | 11/100 [00:02&lt;00:19,  4.46it/s]\nSpectral gap: 0.030771533773091123:  12%|\u2588\u258d          | 12/100 [00:02&lt;00:20,  4.23it/s]\nSpectral gap: 0.05737213734516458:  12%|\u2588\u258c           | 12/100 [00:02&lt;00:20,  4.23it/s]\nSpectral gap: 0.05737213734516458:  13%|\u2588\u258b           | 13/100 [00:02&lt;00:21,  4.07it/s]\nSpectral gap: 0.08388828328501464:  13%|\u2588\u258b           | 13/100 [00:02&lt;00:21,  4.07it/s]\nSpectral gap: 0.08388828328501464:  14%|\u2588\u258a           | 14/100 [00:02&lt;00:21,  4.02it/s]\nSpectral gap: 0.11328186591901049:  14%|\u2588\u258a           | 14/100 [00:02&lt;00:21,  4.02it/s]\nSpectral gap: 0.11328186591901049:  15%|\u2588\u2589           | 15/100 [00:02&lt;00:21,  3.94it/s]\nSpectral gap: 0.14913527084928568:  15%|\u2588\u2589           | 15/100 [00:03&lt;00:21,  3.94it/s]\nSpectral gap: 0.14913527084928568:  16%|\u2588\u2588           | 16/100 [00:03&lt;00:21,  3.91it/s]\nSpectral gap: 0.19706223034570425:  16%|\u2588\u2588           | 16/100 [00:03&lt;00:21,  3.91it/s]\nSpectral gap: 0.19706223034570425:  17%|\u2588\u2588\u258f          | 17/100 [00:03&lt;00:21,  3.87it/s]\nSpectral gap: 0.2682296728912812:  17%|\u2588\u2588\u258d           | 17/100 [00:03&lt;00:21,  3.87it/s]\nSpectral gap: 0.2682296728912812:  18%|\u2588\u2588\u258c           | 18/100 [00:03&lt;00:21,  3.86it/s]\nSpectral gap: 0.39110971077861834:  18%|\u2588\u2588\u258e          | 18/100 [00:03&lt;00:21,  3.86it/s]\nSpectral gap: 0.39110971077861834:  19%|\u2588\u2588\u258d          | 19/100 [00:03&lt;00:21,  3.86it/s]\nSpectral gap: 0.6704764190216516:  19%|\u2588\u2588\u258b           | 19/100 [00:04&lt;00:21,  3.86it/s]\nSpectral gap: 0.6704764190216516:  20%|\u2588\u2588\u258a           | 20/100 [00:04&lt;00:20,  3.88it/s]\nSpectral gap: 2.079697605957135:  20%|\u2588\u2588\u2588            | 20/100 [00:04&lt;00:20,  3.88it/s]\nSpectral gap: 2.079697605957135:  21%|\u2588\u2588\u2588\u258f           | 21/100 [00:04&lt;00:20,  3.87it/s]\nSpectral gap: 1.9290011460818919:  21%|\u2588\u2588\u2589           | 21/100 [00:04&lt;00:20,  3.87it/s]\nSpectral gap: 1.9290011460818919:  22%|\u2588\u2588\u2588           | 22/100 [00:04&lt;00:20,  3.85it/s]\nSpectral gap: 0.6465649029298314:  22%|\u2588\u2588\u2588           | 22/100 [00:05&lt;00:20,  3.85it/s]\nSpectral gap: 0.6465649029298314:  23%|\u2588\u2588\u2588\u258f          | 23/100 [00:05&lt;00:19,  3.85it/s]\nSpectral gap: 0.378170835351169:  23%|\u2588\u2588\u2588\u258d           | 23/100 [00:05&lt;00:19,  3.85it/s]\nSpectral gap: 0.378170835351169:  24%|\u2588\u2588\u2588\u258c           | 24/100 [00:05&lt;00:18,  4.16it/s]\nSpectral gap: 0.2594624447179541:  24%|\u2588\u2588\u2588\u258e          | 24/100 [00:05&lt;00:18,  4.16it/s]\nSpectral gap: 0.2594624447179541:  25%|\u2588\u2588\u2588\u258c          | 25/100 [00:05&lt;00:15,  4.79it/s]\nSpectral gap: 0.19146257883566434:  25%|\u2588\u2588\u2588\u258e         | 25/100 [00:05&lt;00:15,  4.79it/s]\nSpectral gap: 0.19146257883566434:  26%|\u2588\u2588\u2588\u258d         | 26/100 [00:05&lt;00:13,  5.39it/s]\nSpectral gap: 0.14697873261647626:  26%|\u2588\u2588\u2588\u258d         | 26/100 [00:05&lt;00:13,  5.39it/s]\nSpectral gap: 0.14697873261647626:  27%|\u2588\u2588\u2588\u258c         | 27/100 [00:05&lt;00:12,  5.91it/s]\nSpectral gap: 0.11550525932310667:  27%|\u2588\u2588\u2588\u258c         | 27/100 [00:05&lt;00:12,  5.91it/s]\nSpectral gap: 0.11550525932310667:  28%|\u2588\u2588\u2588\u258b         | 28/100 [00:05&lt;00:11,  6.33it/s]\nSpectral gap: 0.09211198479917945:  28%|\u2588\u2588\u2588\u258b         | 28/100 [00:05&lt;00:11,  6.33it/s]\nSpectral gap: 0.09211198479917945:  29%|\u2588\u2588\u2588\u258a         | 29/100 [00:05&lt;00:10,  6.66it/s]\nSpectral gap: 0.07415667185335098:  29%|\u2588\u2588\u2588\u258a         | 29/100 [00:06&lt;00:10,  6.66it/s]\nSpectral gap: 0.07415667185335098:  30%|\u2588\u2588\u2588\u2589         | 30/100 [00:06&lt;00:10,  6.82it/s]\nSpectral gap: 0.06007720972970835:  30%|\u2588\u2588\u2588\u2589         | 30/100 [00:06&lt;00:10,  6.82it/s]\nSpectral gap: 0.06007720972970835:  31%|\u2588\u2588\u2588\u2588         | 31/100 [00:06&lt;00:10,  6.87it/s]\nSpectral gap: 0.048877214022435445:  31%|\u2588\u2588\u2588\u258b        | 31/100 [00:06&lt;00:10,  6.87it/s]\nSpectral gap: 0.048877214022435445:  32%|\u2588\u2588\u2588\u258a        | 32/100 [00:06&lt;00:09,  6.84it/s]\nSpectral gap: 0.03988005652554547:  32%|\u2588\u2588\u2588\u2588\u258f        | 32/100 [00:06&lt;00:09,  6.84it/s]\nSpectral gap: 0.03988005652554547:  33%|\u2588\u2588\u2588\u2588\u258e        | 33/100 [00:06&lt;00:09,  6.78it/s]\nSpectral gap: 0.03260385406018266:  33%|\u2588\u2588\u2588\u2588\u258e        | 33/100 [00:06&lt;00:09,  6.78it/s]\nSpectral gap: 0.03260385406018266:  34%|\u2588\u2588\u2588\u2588\u258d        | 34/100 [00:06&lt;00:09,  6.71it/s]\nSpectral gap: 0.026692368652848544:  34%|\u2588\u2588\u2588\u2588        | 34/100 [00:06&lt;00:09,  6.71it/s]\nSpectral gap: 0.026692368652848544:  35%|\u2588\u2588\u2588\u2588\u258f       | 35/100 [00:06&lt;00:09,  6.68it/s]\nSpectral gap: 0.021874154013015543:  35%|\u2588\u2588\u2588\u2588\u258f       | 35/100 [00:06&lt;00:09,  6.68it/s]\nSpectral gap: 0.021874154013015543:  36%|\u2588\u2588\u2588\u2588\u258e       | 36/100 [00:06&lt;00:09,  6.75it/s]\nSpectral gap: 0.017937924059742566:  36%|\u2588\u2588\u2588\u2588\u258e       | 36/100 [00:07&lt;00:09,  6.75it/s]\nSpectral gap: 0.017937924059742566:  37%|\u2588\u2588\u2588\u2588\u258d       | 37/100 [00:07&lt;00:09,  6.82it/s]\nSpectral gap: 0.014717396976979493:  37%|\u2588\u2588\u2588\u2588\u258d       | 37/100 [00:07&lt;00:09,  6.82it/s]\nSpectral gap: 0.014717396976979493:  38%|\u2588\u2588\u2588\u2588\u258c       | 38/100 [00:07&lt;00:09,  6.80it/s]\nSpectral gap: 0.012079568450458307:  38%|\u2588\u2588\u2588\u2588\u258c       | 38/100 [00:07&lt;00:09,  6.80it/s]\nSpectral gap: 0.012079568450458307:  39%|\u2588\u2588\u2588\u2588\u258b       | 39/100 [00:07&lt;00:08,  6.83it/s]\nSpectral gap: 0.00991708428900409:  39%|\u2588\u2588\u2588\u2588\u2588        | 39/100 [00:07&lt;00:08,  6.83it/s]\nSpectral gap: 0.00991708428900409:  40%|\u2588\u2588\u2588\u2588\u2588\u258f       | 40/100 [00:07&lt;00:08,  6.78it/s]\nSpectral gap: 0.008143250497765318:  40%|\u2588\u2588\u2588\u2588\u258a       | 40/100 [00:07&lt;00:08,  6.78it/s]\nSpectral gap: 0.008143250497765318:  41%|\u2588\u2588\u2588\u2588\u2589       | 41/100 [00:07&lt;00:08,  6.79it/s]\nSpectral gap: 0.0066878499303776075:  41%|\u2588\u2588\u2588\u2588\u258c      | 41/100 [00:07&lt;00:08,  6.79it/s]\nSpectral gap: 0.0066878499303776075:  42%|\u2588\u2588\u2588\u2588\u258c      | 42/100 [00:07&lt;00:08,  6.92it/s]\nSpectral gap: 0.005492805863886888:  42%|\u2588\u2588\u2588\u2588\u2588       | 42/100 [00:07&lt;00:08,  6.92it/s]\nSpectral gap: 0.005492805863886888:  43%|\u2588\u2588\u2588\u2588\u2588\u258f      | 43/100 [00:07&lt;00:08,  6.92it/s]\nSpectral gap: 0.004511920780915883:  43%|\u2588\u2588\u2588\u2588\u2588\u258f      | 43/100 [00:08&lt;00:08,  6.92it/s]\nSpectral gap: 0.004511920780915883:  44%|\u2588\u2588\u2588\u2588\u2588\u258e      | 44/100 [00:08&lt;00:08,  6.85it/s]\nSpectral gap: 0.0037064357249065715:  44%|\u2588\u2588\u2588\u2588\u258a      | 44/100 [00:08&lt;00:08,  6.85it/s]\nSpectral gap: 0.0037064357249065715:  45%|\u2588\u2588\u2588\u2588\u2589      | 45/100 [00:08&lt;00:07,  6.89it/s]\nSpectral gap: 0.003044861506334771:  45%|\u2588\u2588\u2588\u2588\u2588\u258d      | 45/100 [00:08&lt;00:07,  6.89it/s]\nSpectral gap: 0.003044861506334771:  46%|\u2588\u2588\u2588\u2588\u2588\u258c      | 46/100 [00:08&lt;00:07,  7.09it/s]\nSpectral gap: 0.002501603022987549:  46%|\u2588\u2588\u2588\u2588\u2588\u258c      | 46/100 [00:08&lt;00:07,  7.09it/s]\nSpectral gap: 0.002501603022987549:  47%|\u2588\u2588\u2588\u2588\u2588\u258b      | 47/100 [00:08&lt;00:07,  7.25it/s]\nSpectral gap: 0.00205539177335859:  47%|\u2588\u2588\u2588\u2588\u2588\u2588       | 47/100 [00:08&lt;00:07,  7.25it/s]\nSpectral gap: 0.00205539177335859:  48%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f      | 48/100 [00:08&lt;00:07,  7.32it/s]\nSpectral gap: 0.0016882919932496086:  48%|\u2588\u2588\u2588\u2588\u2588\u258e     | 48/100 [00:08&lt;00:07,  7.32it/s]\nSpectral gap: 0.0016882919932496086:  49%|\u2588\u2588\u2588\u2588\u2588\u258d     | 49/100 [00:08&lt;00:06,  7.34it/s]\nSpectral gap: 0.0013872037816450257:  49%|\u2588\u2588\u2588\u2588\u2588\u258d     | 49/100 [00:08&lt;00:06,  7.34it/s]\nSpectral gap: 0.0013872037816450257:  50%|\u2588\u2588\u2588\u2588\u2588\u258c     | 50/100 [00:08&lt;00:06,  7.32it/s]\nSpectral gap: 0.0011399207493945171:  50%|\u2588\u2588\u2588\u2588\u2588\u258c     | 50/100 [00:09&lt;00:06,  7.32it/s]\nSpectral gap: 0.0011399207493945171:  51%|\u2588\u2588\u2588\u2588\u2588\u258c     | 51/100 [00:09&lt;00:06,  7.24it/s]\nSpectral gap: 0.0009365524035984121:  51%|\u2588\u2588\u2588\u2588\u2588\u258c     | 51/100 [00:09&lt;00:06,  7.24it/s]\nEigenvectors computed:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b         | 2/3 [00:10&lt;00:05,  5.92s/it]\nIteration:   0%|                                              | 0/100 [00:00&lt;?, ?it/s]\nIteration:   1%|\u258d                                     | 1/100 [00:00&lt;00:20,  4.85it/s]\nSpectral gap: 241.18247703177144:   1%|\u258f              | 1/100 [00:00&lt;00:20,  4.85it/s]\nSpectral gap: 241.18247703177144:   2%|\u258e              | 2/100 [00:00&lt;00:23,  4.14it/s]\nSpectral gap: 1.1663354566621487:   2%|\u258e              | 2/100 [00:00&lt;00:23,  4.14it/s]\nSpectral gap: 1.1663354566621487:   3%|\u258d              | 3/100 [00:00&lt;00:24,  3.97it/s]\nSpectral gap: 0.6824635010861562:   3%|\u258d              | 3/100 [00:00&lt;00:24,  3.97it/s]\nSpectral gap: 0.6824635010861562:   4%|\u258c              | 4/100 [00:00&lt;00:24,  3.91it/s]\nSpectral gap: 5.013314000281176:   4%|\u258b               | 4/100 [00:01&lt;00:24,  3.91it/s]\nSpectral gap: 5.013314000281176:   5%|\u258a               | 5/100 [00:01&lt;00:24,  3.88it/s]\nSpectral gap: 1.3211244534095679:   5%|\u258a              | 5/100 [00:01&lt;00:24,  3.88it/s]\nSpectral gap: 1.3211244534095679:   6%|\u2589              | 6/100 [00:01&lt;00:24,  3.86it/s]\nSpectral gap: 0.4319394479434034:   6%|\u2589              | 6/100 [00:01&lt;00:24,  3.86it/s]\nSpectral gap: 0.4319394479434034:   7%|\u2588              | 7/100 [00:01&lt;00:24,  3.84it/s]\nSpectral gap: 0.19227522361333102:   7%|\u2589             | 7/100 [00:02&lt;00:24,  3.84it/s]\nSpectral gap: 0.19227522361333102:   8%|\u2588             | 8/100 [00:02&lt;00:24,  3.83it/s]\nSpectral gap: 0.09423674720709461:   8%|\u2588             | 8/100 [00:02&lt;00:24,  3.83it/s]\nSpectral gap: 0.09423674720709461:   9%|\u2588\u258e            | 9/100 [00:02&lt;00:23,  3.81it/s]\nSpectral gap: 0.04852638857367241:   9%|\u2588\u258e            | 9/100 [00:02&lt;00:23,  3.81it/s]\nSpectral gap: 0.04852638857367241:  10%|\u2588\u258e           | 10/100 [00:02&lt;00:23,  3.81it/s]\nSpectral gap: 0.025861557422916102:  10%|\u2588\u258f          | 10/100 [00:02&lt;00:23,  3.81it/s]\nSpectral gap: 0.025861557422916102:  11%|\u2588\u258e          | 11/100 [00:02&lt;00:23,  3.80it/s]\nSpectral gap: 0.014180306348438426:  11%|\u2588\u258e          | 11/100 [00:03&lt;00:23,  3.80it/s]\nSpectral gap: 0.014180306348438426:  12%|\u2588\u258d          | 12/100 [00:03&lt;00:23,  3.79it/s]\nSpectral gap: 0.007978698200502057:  12%|\u2588\u258d          | 12/100 [00:03&lt;00:23,  3.79it/s]\nSpectral gap: 0.007978698200502057:  13%|\u2588\u258c          | 13/100 [00:03&lt;00:23,  3.77it/s]\nSpectral gap: 0.004599146156083687:  13%|\u2588\u258c          | 13/100 [00:03&lt;00:23,  3.77it/s]\nSpectral gap: 0.004599146156083687:  14%|\u2588\u258b          | 14/100 [00:03&lt;00:22,  3.78it/s]\nSpectral gap: 0.0027128767883270095:  14%|\u2588\u258c         | 14/100 [00:03&lt;00:22,  3.78it/s]\nSpectral gap: 0.0027128767883270095:  15%|\u2588\u258b         | 15/100 [00:03&lt;00:22,  3.76it/s]\nSpectral gap: 0.0016353614633023042:  15%|\u2588\u258b         | 15/100 [00:04&lt;00:22,  3.76it/s]\nSpectral gap: 0.0016353614633023042:  16%|\u2588\u258a         | 16/100 [00:04&lt;00:22,  3.80it/s]\nSpectral gap: 0.0010055447923407108:  16%|\u2588\u258a         | 16/100 [00:04&lt;00:22,  3.80it/s]\nSpectral gap: 0.0010055447923407108:  17%|\u2588\u258a         | 17/100 [00:04&lt;00:21,  3.83it/s]\nSpectral gap: 0.0006301425099729107:  17%|\u2588\u258a         | 17/100 [00:04&lt;00:21,  3.83it/s]\nEigenvectors computed: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:15&lt;00:00,  5.04s/it]\n</pre> In\u00a0[22]: Copied! <pre>print(evals)\n</pre> print(evals) <pre>[-162.9615478515625, -99.86493682861328, 90.47868347167969]\n</pre> In\u00a0[23]: Copied! <pre>landscape = LossLandscape.compute(\n    rnn,\n    data,\n    evecs,\n    loss_function, # loss function\n    dim=2,\n    distance=0.5,\n    device=device,\n)\n</pre> landscape = LossLandscape.compute(     rnn,     data,     evecs,     loss_function, # loss function     dim=2,     distance=0.5,     device=device, ) <pre>Computing 1681 points in 2D space...\n</pre> <pre>Computing 2D landscape: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1681/1681 [00:22&lt;00:00, 73.71it/s]</pre> <pre>Loss hypercube stats - min: 4.7444376945495605, max: 11.950156211853027, mean: 7.034827068687407\n</pre> <pre>\n</pre> In\u00a0[24]: Copied! <pre>landscape.save(\"example.npz\")\n</pre> landscape.save(\"example.npz\") In\u00a0[25]: Copied! <pre>landscape  = LossLandscape.load_from_npz(\"example.npz\")\n</pre> landscape  = LossLandscape.load_from_npz(\"example.npz\") In\u00a0[26]: Copied! <pre>landscape.show()\n</pre> landscape.show() <pre>Attempting log-scale surface plot...\n</pre> In\u00a0[38]: Copied! <pre>landscape.show_profile()\n</pre> landscape.show_profile() Out[38]: In\u00a0[28]: Copied! <pre>landscape.show_contour()\n</pre> landscape.show_contour() In\u00a0[29]: Copied! <pre>landscape.show_persistence_barcode()\n</pre> landscape.show_persistence_barcode() In\u00a0[30]: Copied! <pre># we can use this function to convert the merge tree \n# into a networkx graph and visualize it!\nfrom landscaper.tda import digraph_mt\ng = digraph_mt(landscape.get_sublevel_tree())\n</pre> # we can use this function to convert the merge tree  # into a networkx graph and visualize it! from landscaper.tda import digraph_mt g = digraph_mt(landscape.get_sublevel_tree()) In\u00a0[31]: Copied! <pre>import networkx as nx\nnx.draw_planar(g, with_labels=True)\n</pre> import networkx as nx nx.draw_planar(g, with_labels=True) In\u00a0[32]: Copied! <pre>landscape.smad()\n</pre> landscape.smad() Out[32]: <pre>0.05093240737915039</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/rnn/#computing-a-loss-landscape-for-an-rnn","title":"Computing a Loss Landscape for an RNN\u00b6","text":""},{"location":"notebooks/rnn/#building-and-training-the-model","title":"Building and training the model\u00b6","text":""},{"location":"notebooks/rnn/#computing-the-landscape","title":"Computing the landscape\u00b6","text":""},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>landscaper<ul> <li>compute</li> <li>hessian</li> <li>landscape</li> <li>plots</li> <li>tda</li> <li>topology_profile</li> <li>utils</li> </ul> </li> </ul>"},{"location":"reference/landscaper/","title":"landscaper","text":"<p>Landscaper is a comprehensive Python framework designed for exploring the loss landscapes of deep learning models.</p>"},{"location":"reference/landscaper/compute/","title":"compute","text":"<p>Module for computing loss landscapes for PyTorch models.</p>"},{"location":"reference/landscaper/compute/#landscaper.compute.add_direction","title":"<code>add_direction(parameters, direction)</code>","text":"<p>Add a direction to parameters in-place.</p> <p>Parameters:</p> Name Type Description Default <code>parameters</code> <code>list[Tensor]</code> <p>List of model parameters to modify.</p> required <code>direction</code> <code>list[Tensor]</code> <p>List of direction tensors to add to the parameters.</p> required Source code in <code>src/landscaper/compute.py</code> <pre><code>def add_direction(\n    parameters: list[torch.Tensor], direction: list[torch.Tensor]\n) -&gt; None:\n    \"\"\"Add a direction to parameters in-place.\n\n    Args:\n        parameters (list[torch.Tensor]): List of model parameters to modify.\n        direction (list[torch.Tensor]): List of direction tensors to add to the parameters.\n    \"\"\"\n    for p, d in zip(parameters, direction, strict=False):\n        p.add_(d)\n</code></pre>"},{"location":"reference/landscaper/compute/#landscaper.compute.clone_parameters","title":"<code>clone_parameters(parameters, as_complex)</code>","text":"<p>Clone model parameters to avoid modifying the original tensors.</p> <p>Parameters:</p> Name Type Description Default <code>parameters</code> <code>list[Tensor]</code> <p>List of model parameters to clone.</p> required <code>as_complex</code> <code>bool</code> <p>If True, convert cloned parameters to complex tensors. If False, keep them as real tensors.</p> required <p>Returns:</p> Type Description <code>list[Tensor]</code> <p>list[torch.Tensor]: List of cloned parameters.</p> Source code in <code>src/landscaper/compute.py</code> <pre><code>def clone_parameters(\n    parameters: list[torch.Tensor], as_complex: bool\n) -&gt; list[torch.Tensor]:\n    \"\"\"Clone model parameters to avoid modifying the original tensors.\n\n    Args:\n        parameters (list[torch.Tensor]): List of model parameters to clone.\n        as_complex (bool): If True, convert cloned parameters to complex tensors. If False, keep them as real tensors.\n\n    Returns:\n        list[torch.Tensor]: List of cloned parameters.\n    \"\"\"\n    params = [p.clone() for p in parameters]\n\n    if as_complex:\n        params = [\n            torch.complex(p, torch.zeros_like(p)) if not torch.is_complex(p) else p\n            for p in params\n        ]\n    return params\n</code></pre>"},{"location":"reference/landscaper/compute/#landscaper.compute.compute_loss_landscape","title":"<code>compute_loss_landscape(model, data, dirs, scalar_fn, steps=41, distance=0.01, dim=3, device='cuda', use_complex=False)</code>","text":"<p>Computes the loss landscape along the top-N eigenvector directions.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The model to analyze.</p> required <code>data</code> <code>ArrayLike</code> <p>Data that will be used to evaluate the loss function for each point on the landscape.</p> required <code>dirs</code> <code>ArrayLike</code> <p>2D array of directions to generate the landscape with.</p> required <code>scalar_fn</code> <code>Callable[[Module, ArrayLike], float]</code> <p>This function should take a model and your data and return a scalar value; it gets called repeatedly with perturbed versions of the model.</p> required <code>steps</code> <code>int</code> <p>Number of steps in each dimension.</p> <code>41</code> <code>distance</code> <code>float</code> <p>Total distance to travel in parameter space. Setting this value too high may lead to unreliable results.</p> <code>0.01</code> <code>dim</code> <code>int</code> <p>Number of dimensions for the loss landscape (default: 3)</p> <code>3</code> <code>device</code> <code>Literal[cuda, cpu]</code> <p>Device used to compute landscape.</p> <code>'cuda'</code> <code>use_complex</code> <code>bool</code> <p>Computes Landscape using complex numbers if this is set to true; use if your directions are complex.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[ArrayLike, ArrayLike]</code> <p>The loss values and coordinates for the landscape as numpy arrays.</p> Source code in <code>src/landscaper/compute.py</code> <pre><code>def compute_loss_landscape(\n    model: torch.nn.Module,\n    data: npt.ArrayLike,\n    dirs: npt.ArrayLike,\n    scalar_fn: Callable[[torch.nn.Module, npt.ArrayLike], float],\n    steps: int = 41,\n    distance: float = 0.01,\n    dim: int = 3,\n    device: DeviceStr = \"cuda\",\n    use_complex: bool = False,\n) -&gt; tuple[npt.ArrayLike, npt.ArrayLike]:\n    \"\"\"Computes the loss landscape along the top-N eigenvector directions.\n\n    Args:\n        model (torch.nn.Module): The model to analyze.\n        data (npt.ArrayLike): Data that will be used to evaluate the loss function for each point on the landscape.\n        dirs (npt.ArrayLike): 2D array of directions to generate the landscape with.\n        scalar_fn (Callable[[torch.nn.Module, npt.ArrayLike], float]): This function should take a model\n            and your data and return a scalar value; it gets called repeatedly with perturbed versions of the model.\n        steps (int): Number of steps in each dimension.\n        distance (float): Total distance to travel in parameter space. Setting this value too high\n            may lead to unreliable results.\n        dim (int): Number of dimensions for the loss landscape (default: 3)\n        device (Literal[\"cuda\", \"cpu\"]): Device used to compute landscape.\n        use_complex (bool): Computes Landscape using complex numbers if this is set to true;\n            use if your directions are complex.\n\n    Returns:\n        The loss values and coordinates for the landscape as numpy arrays.\n    \"\"\"\n    # Initialize loss hypercube - For dim dimensions, we need a dim-dimensional array\n    loss_shape = tuple([steps] * dim)\n    loss_hypercube = np.zeros(loss_shape)\n\n    coordinates = [np.linspace(-distance, distance, steps) for _ in range(dim)]\n\n    # Compute loss landscape - this is the core logic that needs to be efficient for N dimensions\n    if dim &gt; 5:\n        print(\n            f\"Warning: {dim} dimensions may require significant memory and computation time.\"\n        )\n        print(\n            f\"Consider reducing the 'steps' parameter (currently {steps}) or using a lower dimension.\"\n        )\n\n    with torch.no_grad():\n        # Get starting parameters and save original weights\n        start_point = get_model_parameters(model, use_complex)\n        original_weights = clone_parameters(start_point, use_complex)\n\n        # Get top-N eigenvectors as directions\n        directions = copy.deepcopy(dirs)\n        if dim &gt; len(directions):\n            raise ValueError(\n                f\"Requested dimension {dim} exceeds available directions ({len(directions)}).\"\n            )\n\n        # Normalize all directions\n        for i in range(dim):\n            directions[i] = normalize_direction(directions[i], start_point)\n\n        # Scale directions to match steps and total distance\n        model_norm = get_model_norm(start_point)\n        for i in range(dim):\n            dir_norm = get_model_norm(directions[i])\n            scale_direction(\n                directions[i], ((model_norm * distance) / (steps / 2)) / dir_norm\n            )\n\n        # Generate grid coordinates\n        grid_points = list(product(range(steps), repeat=dim))\n        print(f\"Computing {len(grid_points)} points in {dim}D space...\")\n\n        center_idx = steps // 2\n        try:\n            for gp in tqdm(grid_points, desc=f\"Computing {dim}D landscape\"):\n                # Create a new parameter set for this grid point\n                point_params = clone_parameters(original_weights, use_complex)\n\n                # Move to the specified grid point by adding appropriate steps in each direction\n                for dim_idx, point_idx in enumerate(gp):\n                    steps_from_center = point_idx - center_idx\n\n                    if steps_from_center &gt; 0:\n                        for _ in range(steps_from_center):\n                            add_direction(point_params, directions[dim_idx])\n                    elif steps_from_center &lt; 0:\n                        for _ in range(-steps_from_center):\n                            sub_direction(point_params, directions[dim_idx])\n\n                # Set model parameters\n                set_parameters(model, point_params)\n                loss = scalar_fn(model, data)\n                loss_hypercube[gp] = loss\n\n                # Clear GPU memory\n                if gp[0] % 5 == 0 and device == \"cuda\" and all(x == 0 for x in gp[1:]):\n                    torch.cuda.empty_cache()\n        finally:\n            # Restore original weights\n            set_parameters(model, original_weights)\n\n        # Handle extreme values in loss surface\n        loss_hypercube = np.nan_to_num(\n            loss_hypercube,\n            nan=np.nanmean(loss_hypercube),\n            posinf=np.nanmax(loss_hypercube[~np.isinf(loss_hypercube)]),\n            neginf=np.nanmin(loss_hypercube[~np.isinf(loss_hypercube)]),\n        )\n\n        # Print statistics about the loss hypercube\n        print(\n            f\"Loss hypercube stats - min: {np.min(loss_hypercube)}, max: {np.max(loss_hypercube)}, \"\n            f\"mean: {np.mean(loss_hypercube)}\"\n        )\n\n    return loss_hypercube, coordinates\n</code></pre>"},{"location":"reference/landscaper/compute/#landscaper.compute.get_model_norm","title":"<code>get_model_norm(parameters)</code>","text":"<p>Get L2 norm of parameters.</p> <p>Parameters:</p> Name Type Description Default <code>parameters</code> <code>list[Tensor]</code> <p>List of model parameters.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>L2 norm of the model parameters.</p> Source code in <code>src/landscaper/compute.py</code> <pre><code>def get_model_norm(parameters: list[torch.Tensor]) -&gt; float:\n    \"\"\"Get L2 norm of parameters.\n\n    Args:\n        parameters (list[torch.Tensor]): List of model parameters.\n\n    Returns:\n        float: L2 norm of the model parameters.\n    \"\"\"\n    return torch.sqrt(sum((p**2).sum() for p in parameters))\n</code></pre>"},{"location":"reference/landscaper/compute/#landscaper.compute.get_model_parameters","title":"<code>get_model_parameters(model, as_complex)</code>","text":"<p>Get model parameters as a list of tensors.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The PyTorch model whose parameters are to be retrieved.</p> required <code>as_complex</code> <code>bool</code> <p>If True, convert parameters to complex tensors. If False, keep them as real tensors.</p> required <p>Returns:</p> Type Description <code>list[Tensor]</code> <p>list[torch.Tensor]: List of model parameters.</p> Source code in <code>src/landscaper/compute.py</code> <pre><code>def get_model_parameters(\n    model: torch.nn.Module, as_complex: bool\n) -&gt; list[torch.Tensor]:\n    \"\"\"Get model parameters as a list of tensors.\n\n    Args:\n        model (torch.nn.Module): The PyTorch model whose parameters are to be retrieved.\n        as_complex (bool): If True, convert parameters to complex tensors. If False, keep them as real tensors.\n\n    Returns:\n        list[torch.Tensor]: List of model parameters.\n    \"\"\"\n    params = [p.data for p in model.parameters()]\n\n    if as_complex:\n        params = [\n            torch.complex(p, torch.zeros_like(p)) if not torch.is_complex(p) else p\n            for p in params\n        ]\n    return params\n</code></pre>"},{"location":"reference/landscaper/compute/#landscaper.compute.normalize_direction","title":"<code>normalize_direction(direction, parameters)</code>","text":"<p>Normalize a direction based on the number of parameters.</p> <p>Parameters:</p> Name Type Description Default <code>direction</code> <code>list[Tensor]</code> <p>List of direction tensors to normalize.</p> required <code>parameters</code> <code>list[Tensor]</code> <p>List of model parameters to use for normalization.</p> required <p>Returns:</p> Type Description <code>list[Tensor]</code> <p>list[torch.Tensor]: Normalized direction tensors.</p> Source code in <code>src/landscaper/compute.py</code> <pre><code>def normalize_direction(\n    direction: list[torch.Tensor], parameters: list[torch.Tensor]\n) -&gt; list[torch.Tensor]:\n    \"\"\"Normalize a direction based on the number of parameters.\n\n    Args:\n        direction (list[torch.Tensor]): List of direction tensors to normalize.\n        parameters (list[torch.Tensor]): List of model parameters to use for normalization.\n\n    Returns:\n        list[torch.Tensor]: Normalized direction tensors.\n    \"\"\"\n    for d, p in zip(direction, parameters, strict=False):\n        d.mul_(\n            torch.sqrt(torch.tensor(p.numel(), dtype=torch.float32, device=d.device))\n            / (d.norm() + 1e-10)\n        )\n    return direction\n</code></pre>"},{"location":"reference/landscaper/compute/#landscaper.compute.scale_direction","title":"<code>scale_direction(direction, scale)</code>","text":"<p>Scale a direction by a given factor.</p> <p>Parameters:</p> Name Type Description Default <code>direction</code> <code>list[Tensor]</code> <p>List of direction tensors to scale.</p> required <code>scale</code> <code>float</code> <p>Scaling factor.</p> required <p>Returns:</p> Type Description <code>list[Tensor]</code> <p>list[torch.Tensor]: Scaled direction tensors.</p> Source code in <code>src/landscaper/compute.py</code> <pre><code>def scale_direction(direction: list[torch.Tensor], scale: float) -&gt; list[torch.Tensor]:\n    \"\"\"Scale a direction by a given factor.\n\n    Args:\n        direction (list[torch.Tensor]): List of direction tensors to scale.\n        scale (float): Scaling factor.\n\n    Returns:\n        list[torch.Tensor]: Scaled direction tensors.\n    \"\"\"\n    for d in direction:\n        d.mul_(scale)\n</code></pre>"},{"location":"reference/landscaper/compute/#landscaper.compute.set_parameters","title":"<code>set_parameters(model, parameters)</code>","text":"<p>Set model parameters from a list of tensors.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The PyTorch model whose parameters are to be set.</p> required <code>parameters</code> <code>list[Tensor]</code> <p>List of tensors to set as model parameters.</p> required Source code in <code>src/landscaper/compute.py</code> <pre><code>def set_parameters(model: torch.nn.Module, parameters: list[torch.Tensor]) -&gt; None:\n    \"\"\"Set model parameters from a list of tensors.\n\n    Args:\n        model (torch.nn.Module): The PyTorch model whose parameters are to be set.\n        parameters (list[torch.Tensor]): List of tensors to set as model parameters.\n    \"\"\"\n    for p, new_p in zip(model.parameters(), parameters, strict=False):\n        if not torch.is_complex(p) and torch.is_complex(new_p):\n            new_p = new_p.real\n        p.data.copy_(new_p)\n</code></pre>"},{"location":"reference/landscaper/compute/#landscaper.compute.sub_direction","title":"<code>sub_direction(parameters, direction)</code>","text":"<p>Subtract a direction from parameters in-place.</p> <p>Parameters:</p> Name Type Description Default <code>parameters</code> <code>list[Tensor]</code> <p>List of model parameters to modify.</p> required <code>direction</code> <code>list[Tensor]</code> <p>List of direction tensors to subtract from the parameters.</p> required Source code in <code>src/landscaper/compute.py</code> <pre><code>def sub_direction(\n    parameters: list[torch.Tensor], direction: list[torch.Tensor]\n) -&gt; None:\n    \"\"\"Subtract a direction from parameters in-place.\n\n    Args:\n        parameters (list[torch.Tensor]): List of model parameters to modify.\n        direction (list[torch.Tensor]): List of direction tensors to subtract from the parameters.\n    \"\"\"\n    for p, d in zip(parameters, direction, strict=False):\n        p.sub_(d)\n</code></pre>"},{"location":"reference/landscaper/hessian/","title":"hessian","text":"<p>Module for calculating the hessian.</p> <p>This code was copied and modified from PyHessian (https://github.com/amirgholami/PyHessian/blob/master/pyhessian/hessian.py).</p>"},{"location":"reference/landscaper/hessian/#landscaper.hessian.PyHessian","title":"<code>PyHessian</code>","text":"<p>PyHessian class for computing Hessian-related quantities.</p> <p>This class provides methods to compute eigenvalues, eigenvectors, trace, and density of the Hessian matrix using various methods such as power iteration, Hutchinson's method, and stochastic Lanczos algorithm. It supports different model architectures and can be used with custom data loaders.</p> Source code in <code>src/landscaper/hessian.py</code> <pre><code>class PyHessian:\n    \"\"\"PyHessian class for computing Hessian-related quantities.\n\n    This class provides methods to compute eigenvalues, eigenvectors, trace, and density of the Hessian\n    matrix using various methods such as power iteration, Hutchinson's method, and stochastic Lanczos algorithm.\n    It supports different model architectures and can be used with custom data loaders.\n    \"\"\"\n\n    def __init__(\n        self,\n        model: torch.nn.Module,\n        criterion: torch.nn.Module | torch.Tensor,\n        data: Any,\n        device: DeviceStr,\n        hessian_generator: Callable[\n            [torch.nn.Module, torch.nn.Module | torch.Tensor, Any, DeviceStr, Any],\n            Generator[tuple[int, torch.Tensor], None, None],\n        ] = generic_generator,\n        try_cache: bool = False,\n        use_complex: bool = False,\n    ):\n        \"\"\"Initializes the PyHessian class.\n\n        Args:\n            model (torch.nn.Module): The model for which the Hessian is computed.\n            criterion (torch.nn.Module): The loss function used for training the model.\n            data (torch.utils.data.DataLoader): DataLoader providing the training data.\n            device (DeviceStr): Device to run the computations on (e.g., 'cpu' or 'cuda').\n            hessian_generator (callable, optional): Function to generate per-sample gradients.\n                Defaults to generic_generator.\n            try_cache (bool): Defaults to false. Caches per-sample gradients along with their computational graphs.\n                Should make the computation faster, but can cause out of memory errors. If you run into memory problems,\n                try setting this to false first.\n            use_complex (bool): Defaults to false. Forces the calculator to use complex values when performing\n                computations. This is determined automatically, but this kwarg is included as a backup.\n        \"\"\"\n        if model.training:\n            print(\n                \"Setting model to eval mode. PyHessian will not work with models in training mode!\"\n            )\n            self.model = model.eval()\n        else:\n            self.model = model\n\n        self.gen = hessian_generator\n        self.params = [p for p in model.parameters() if p.requires_grad]\n        self.criterion = criterion\n        self.data = data\n        self.device = device\n        self.use_complex = _is_model_complex(self.model) or use_complex\n\n        if self.use_complex:\n            print(\n                \"Complex parameters detected in model. Results will be complex tensors.\"\n            )\n\n        if try_cache:\n            grad_cache = []\n            for input_size, grads in self.gen(\n                self.model, self.criterion, self.data, self.device\n            ):\n                grad_cache.append((input_size, grads))\n            self.grad_cache = grad_cache\n            self.gen = lambda *args: (x for x in self.grad_cache)\n        else:\n            self.grad_cache = None\n\n    def hv_product(self, v: list[torch.Tensor]) -&gt; tuple[float, list[torch.Tensor]]:\n        \"\"\"Computes the product of the Hessian-vector product (Hv) for the data.\n\n        Args:\n            v (list[torch.Tensor]): A list of tensors representing the vector to multiply with the Hessian.\n\n        Returns:\n            tuple: A tuple containing the eigenvalue (float) and the Hessian-vector product (list of tensors).\n        \"\"\"\n        THv = [torch.zeros_like(p) for p in self.params]  # accumulate result\n\n        if self.use_complex:\n            THv = [\n                torch.complex(t, t.clone()) if not torch.is_complex(t) else t\n                for t in THv\n            ]\n\n        num_data = 0\n        for input_size, grads in self.gen(\n            self.model, self.criterion, self.data, self.device\n        ):\n            if self.use_complex:\n                grads = [\n                    (\n                        torch.complex(g, torch.zeros_like(g))\n                        if not torch.is_complex(g)\n                        else g\n                    )\n                    for g in grads\n                ]\n\n            Hv = torch.autograd.grad(\n                grads,\n                self.params,\n                grad_outputs=v,\n                retain_graph=self.grad_cache is not None,\n            )\n\n            THv = [\n                THv1 + Hv1 * float(input_size) + 0.0\n                for THv1, Hv1 in zip(THv, Hv, strict=False)\n            ]\n            num_data += float(input_size)\n\n        THv = [THv1 / float(num_data) for THv1 in THv]\n        eigenvalue = group_product(THv, v).cpu().item()\n        return eigenvalue, THv\n\n    def eigenvalues(\n        self,\n        maxIter: int = 100,\n        tol: float = 1e-3,\n        top_n: int = 1,\n    ) -&gt; tuple[list[float], list[list[torch.Tensor]]]:\n        \"\"\"Computes the top_n eigenvalues using power iteration method.\n\n        Args:\n            maxIter (int, optional): Maximum iterations used to compute each single eigenvalue. Defaults to 100.\n            tol (float, optional): The relative tolerance between two consecutive eigenvalue computations\n                from power iteration. Defaults to 1e-3.\n            top_n (int, optional): The number of top eigenvalues to compute. Defaults to 1.\n\n        Returns:\n            tuple[list[float], list[list[torch.Tensor]]]: A tuple containing the eigenvalues and\n                their corresponding eigenvectors.\n        \"\"\"\n        assert top_n &gt;= 1 and not self.model.training\n        eigenvalues = []\n        eigenvectors = []\n\n        with tqdm(total=top_n, desc=\"Eigenvectors computed\", leave=True) as pbar:\n            computed_dim = 0\n\n            while computed_dim &lt; top_n:\n                eigenvalue = None\n                v = [torch.randn_like(p) for p in self.params]  # generate random vector\n\n                if self.use_complex:\n                    v = [\n                        (\n                            torch.complex(vv, torch.randn_like(vv))\n                            if not torch.is_complex(vv)\n                            else vv\n                        )\n                        for vv in v\n                    ]\n\n                v = normalization(v)  # normalize the vector\n\n                ibar = tqdm(\n                    range(maxIter),\n                    total=maxIter,\n                    desc=\"Iteration\",\n                    leave=False,\n                    position=1,\n                )\n                for _ in ibar:\n                    v = orthnormal(v, eigenvectors)\n\n                    tmp_eigenvalue, Hv = self.hv_product(v)\n                    v = normalization(Hv)\n\n                    if eigenvalue is None:\n                        eigenvalue = tmp_eigenvalue\n                    else:\n                        spec_gap = abs(eigenvalue - tmp_eigenvalue) / (\n                            abs(eigenvalue) + 1e-6\n                        )\n                        ibar.set_description(f\"Spectral gap: {spec_gap}\")\n                        if spec_gap &lt; tol:\n                            break\n                        else:\n                            eigenvalue = tmp_eigenvalue\n                eigenvalues.append(eigenvalue)\n                eigenvectors.append(v)\n                computed_dim += 1\n\n                pbar.update(1)\n\n        return eigenvalues, eigenvectors\n\n    def trace(self, maxIter: int = 100, tol: float = 1e-3) -&gt; list[float]:\n        \"\"\"Computes the trace of the Hessian using Hutchinson's method.\n\n        Args:\n            maxIter (int): Maximum iterations used to compute the trace. Defaults to 100.\n            tol (float): The relative tolerance for convergence. Defaults to 1e-3.\n\n        Returns:\n            list[float]: A list containing the trace of the Hessian computed over the iterations.\n        \"\"\"\n        assert not self.model.training\n\n        trace_vhv = []\n        trace = 0.0\n\n        for _ in range(maxIter):\n            v = [torch.randint_like(p, high=2) for p in self.params]\n\n            if self.use_complex:\n                v = [\n                    (\n                        torch.complex(vv, torch.randint_like(vv, high=2))\n                        if not torch.is_complex(vv)\n                        else vv\n                    )\n                    for vv in v\n                ]\n\n            # generate Rademacher random variables\n            for v_i in v:\n                v_i[v_i == 0] = -1\n            _, Hv = self.hv_product(v)\n            trace_vhv.append(group_product(Hv, v).cpu().item())\n            if abs(np.mean(trace_vhv) - trace) / (abs(trace) + 1e-6) &lt; tol:\n                return trace_vhv\n            else:\n                trace = np.mean(trace_vhv)\n\n        return trace_vhv\n\n    def density(\n        self, iter: int = 100, n_v: int = 1\n    ) -&gt; tuple[list[list[float]], list[list[float]]]:\n        \"\"\"Computes the estimated eigenvalue density using the stochastic Lanczos algorithm (SLQ).\n\n        Args:\n            iter (int): Number of iterations used to compute the trace. Defaults to 100.\n            n_v (int): Number of SLQ runs. Defaults to 1.\n\n        Returns:\n            tuple[list[list[float]], list[list[float]]]: A tuple containing two lists:\n                - eigen_list_full: List of eigenvalues from each SLQ run.\n                - weight_list_full: List of weights corresponding to the eigenvalues.\n        \"\"\"\n        assert not self.model.training\n\n        device = self.device\n        eigen_list_full = []\n        weight_list_full = []\n\n        for _ in range(n_v):\n            v = [torch.randint_like(p, high=2) for p in self.params]\n\n            if self.use_complex:\n                v = [\n                    (\n                        torch.complex(vv, torch.randint_like(vv, high=2))\n                        if not torch.is_complex(vv)\n                        else vv\n                    )\n                    for vv in v\n                ]\n\n            # generate Rademacher random variables\n            for v_i in v:\n                v_i[v_i == 0] = -1\n            v = normalization(v)\n\n            # standard lanczos algorithm initlization\n            v_list = [v]\n            w_list = []\n            alpha_list = []\n            beta_list = []\n            ############### Lanczos\n            for i in range(iter):\n                w_prime = [torch.zeros_like(p) for p in self.params]\n\n                if self.use_complex:\n                    w_prime = [\n                        (\n                            torch.complex(vv, torch.zeros_like(vv))\n                            if not torch.is_complex(vv)\n                            else vv\n                        )\n                        for vv in w_prime\n                    ]\n\n                if i == 0:\n                    _, w_prime = self.hv_product(v)\n                    alpha = group_product(w_prime, v)\n                    alpha_list.append(alpha.cpu().item())\n                    w = group_add(w_prime, v, alpha=-alpha)\n                    w_list.append(w)\n                else:\n                    beta = torch.sqrt(group_product(w, w))\n                    beta_list.append(beta.cpu().item())\n                    if beta_list[-1] != 0.0:\n                        # We should re-orth it\n                        v = orthnormal(w, v_list)\n                        v_list.append(v)\n                    else:\n                        # generate a new vector\n                        w = [torch.randn_like(p) for p in self.params]\n                        if self.use_complex:\n                            w = [\n                                (\n                                    torch.complex(vv, torch.randn_like(vv))\n                                    if not torch.is_complex(vv)\n                                    else vv\n                                )\n                                for vv in w\n                            ]\n\n                        v = orthnormal(w, v_list)\n                        v_list.append(v)\n                    _, w_prime = self.hv_product(v)\n                    alpha = group_product(w_prime, v)\n                    alpha_list.append(alpha.cpu().item())\n                    w_tmp = group_add(w_prime, v, alpha=-alpha)\n                    w = group_add(w_tmp, v_list[-2], alpha=-beta)\n\n            T = torch.zeros(iter, iter).to(device)\n            for i in range(len(alpha_list)):\n                T[i, i] = alpha_list[i]\n                if i &lt; len(alpha_list) - 1:\n                    T[i + 1, i] = beta_list[i]\n                    T[i, i + 1] = beta_list[i]\n            a_, b_ = torch.linalg.eig(T)\n\n            eigen_list = a_\n            weight_list = torch.pow(b_, 2)\n            eigen_list_full.append(list(eigen_list.cpu().numpy()))\n            weight_list_full.append(list(weight_list.cpu().numpy()))\n\n        return eigen_list_full, weight_list_full\n</code></pre>"},{"location":"reference/landscaper/hessian/#landscaper.hessian.PyHessian.__init__","title":"<code>__init__(model, criterion, data, device, hessian_generator=generic_generator, try_cache=False, use_complex=False)</code>","text":"<p>Initializes the PyHessian class.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The model for which the Hessian is computed.</p> required <code>criterion</code> <code>Module</code> <p>The loss function used for training the model.</p> required <code>data</code> <code>DataLoader</code> <p>DataLoader providing the training data.</p> required <code>device</code> <code>DeviceStr</code> <p>Device to run the computations on (e.g., 'cpu' or 'cuda').</p> required <code>hessian_generator</code> <code>callable</code> <p>Function to generate per-sample gradients. Defaults to generic_generator.</p> <code>generic_generator</code> <code>try_cache</code> <code>bool</code> <p>Defaults to false. Caches per-sample gradients along with their computational graphs. Should make the computation faster, but can cause out of memory errors. If you run into memory problems, try setting this to false first.</p> <code>False</code> <code>use_complex</code> <code>bool</code> <p>Defaults to false. Forces the calculator to use complex values when performing computations. This is determined automatically, but this kwarg is included as a backup.</p> <code>False</code> Source code in <code>src/landscaper/hessian.py</code> <pre><code>def __init__(\n    self,\n    model: torch.nn.Module,\n    criterion: torch.nn.Module | torch.Tensor,\n    data: Any,\n    device: DeviceStr,\n    hessian_generator: Callable[\n        [torch.nn.Module, torch.nn.Module | torch.Tensor, Any, DeviceStr, Any],\n        Generator[tuple[int, torch.Tensor], None, None],\n    ] = generic_generator,\n    try_cache: bool = False,\n    use_complex: bool = False,\n):\n    \"\"\"Initializes the PyHessian class.\n\n    Args:\n        model (torch.nn.Module): The model for which the Hessian is computed.\n        criterion (torch.nn.Module): The loss function used for training the model.\n        data (torch.utils.data.DataLoader): DataLoader providing the training data.\n        device (DeviceStr): Device to run the computations on (e.g., 'cpu' or 'cuda').\n        hessian_generator (callable, optional): Function to generate per-sample gradients.\n            Defaults to generic_generator.\n        try_cache (bool): Defaults to false. Caches per-sample gradients along with their computational graphs.\n            Should make the computation faster, but can cause out of memory errors. If you run into memory problems,\n            try setting this to false first.\n        use_complex (bool): Defaults to false. Forces the calculator to use complex values when performing\n            computations. This is determined automatically, but this kwarg is included as a backup.\n    \"\"\"\n    if model.training:\n        print(\n            \"Setting model to eval mode. PyHessian will not work with models in training mode!\"\n        )\n        self.model = model.eval()\n    else:\n        self.model = model\n\n    self.gen = hessian_generator\n    self.params = [p for p in model.parameters() if p.requires_grad]\n    self.criterion = criterion\n    self.data = data\n    self.device = device\n    self.use_complex = _is_model_complex(self.model) or use_complex\n\n    if self.use_complex:\n        print(\n            \"Complex parameters detected in model. Results will be complex tensors.\"\n        )\n\n    if try_cache:\n        grad_cache = []\n        for input_size, grads in self.gen(\n            self.model, self.criterion, self.data, self.device\n        ):\n            grad_cache.append((input_size, grads))\n        self.grad_cache = grad_cache\n        self.gen = lambda *args: (x for x in self.grad_cache)\n    else:\n        self.grad_cache = None\n</code></pre>"},{"location":"reference/landscaper/hessian/#landscaper.hessian.PyHessian.density","title":"<code>density(iter=100, n_v=1)</code>","text":"<p>Computes the estimated eigenvalue density using the stochastic Lanczos algorithm (SLQ).</p> <p>Parameters:</p> Name Type Description Default <code>iter</code> <code>int</code> <p>Number of iterations used to compute the trace. Defaults to 100.</p> <code>100</code> <code>n_v</code> <code>int</code> <p>Number of SLQ runs. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>tuple[list[list[float]], list[list[float]]]</code> <p>tuple[list[list[float]], list[list[float]]]: A tuple containing two lists: - eigen_list_full: List of eigenvalues from each SLQ run. - weight_list_full: List of weights corresponding to the eigenvalues.</p> Source code in <code>src/landscaper/hessian.py</code> <pre><code>def density(\n    self, iter: int = 100, n_v: int = 1\n) -&gt; tuple[list[list[float]], list[list[float]]]:\n    \"\"\"Computes the estimated eigenvalue density using the stochastic Lanczos algorithm (SLQ).\n\n    Args:\n        iter (int): Number of iterations used to compute the trace. Defaults to 100.\n        n_v (int): Number of SLQ runs. Defaults to 1.\n\n    Returns:\n        tuple[list[list[float]], list[list[float]]]: A tuple containing two lists:\n            - eigen_list_full: List of eigenvalues from each SLQ run.\n            - weight_list_full: List of weights corresponding to the eigenvalues.\n    \"\"\"\n    assert not self.model.training\n\n    device = self.device\n    eigen_list_full = []\n    weight_list_full = []\n\n    for _ in range(n_v):\n        v = [torch.randint_like(p, high=2) for p in self.params]\n\n        if self.use_complex:\n            v = [\n                (\n                    torch.complex(vv, torch.randint_like(vv, high=2))\n                    if not torch.is_complex(vv)\n                    else vv\n                )\n                for vv in v\n            ]\n\n        # generate Rademacher random variables\n        for v_i in v:\n            v_i[v_i == 0] = -1\n        v = normalization(v)\n\n        # standard lanczos algorithm initlization\n        v_list = [v]\n        w_list = []\n        alpha_list = []\n        beta_list = []\n        ############### Lanczos\n        for i in range(iter):\n            w_prime = [torch.zeros_like(p) for p in self.params]\n\n            if self.use_complex:\n                w_prime = [\n                    (\n                        torch.complex(vv, torch.zeros_like(vv))\n                        if not torch.is_complex(vv)\n                        else vv\n                    )\n                    for vv in w_prime\n                ]\n\n            if i == 0:\n                _, w_prime = self.hv_product(v)\n                alpha = group_product(w_prime, v)\n                alpha_list.append(alpha.cpu().item())\n                w = group_add(w_prime, v, alpha=-alpha)\n                w_list.append(w)\n            else:\n                beta = torch.sqrt(group_product(w, w))\n                beta_list.append(beta.cpu().item())\n                if beta_list[-1] != 0.0:\n                    # We should re-orth it\n                    v = orthnormal(w, v_list)\n                    v_list.append(v)\n                else:\n                    # generate a new vector\n                    w = [torch.randn_like(p) for p in self.params]\n                    if self.use_complex:\n                        w = [\n                            (\n                                torch.complex(vv, torch.randn_like(vv))\n                                if not torch.is_complex(vv)\n                                else vv\n                            )\n                            for vv in w\n                        ]\n\n                    v = orthnormal(w, v_list)\n                    v_list.append(v)\n                _, w_prime = self.hv_product(v)\n                alpha = group_product(w_prime, v)\n                alpha_list.append(alpha.cpu().item())\n                w_tmp = group_add(w_prime, v, alpha=-alpha)\n                w = group_add(w_tmp, v_list[-2], alpha=-beta)\n\n        T = torch.zeros(iter, iter).to(device)\n        for i in range(len(alpha_list)):\n            T[i, i] = alpha_list[i]\n            if i &lt; len(alpha_list) - 1:\n                T[i + 1, i] = beta_list[i]\n                T[i, i + 1] = beta_list[i]\n        a_, b_ = torch.linalg.eig(T)\n\n        eigen_list = a_\n        weight_list = torch.pow(b_, 2)\n        eigen_list_full.append(list(eigen_list.cpu().numpy()))\n        weight_list_full.append(list(weight_list.cpu().numpy()))\n\n    return eigen_list_full, weight_list_full\n</code></pre>"},{"location":"reference/landscaper/hessian/#landscaper.hessian.PyHessian.eigenvalues","title":"<code>eigenvalues(maxIter=100, tol=0.001, top_n=1)</code>","text":"<p>Computes the top_n eigenvalues using power iteration method.</p> <p>Parameters:</p> Name Type Description Default <code>maxIter</code> <code>int</code> <p>Maximum iterations used to compute each single eigenvalue. Defaults to 100.</p> <code>100</code> <code>tol</code> <code>float</code> <p>The relative tolerance between two consecutive eigenvalue computations from power iteration. Defaults to 1e-3.</p> <code>0.001</code> <code>top_n</code> <code>int</code> <p>The number of top eigenvalues to compute. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>tuple[list[float], list[list[Tensor]]]</code> <p>tuple[list[float], list[list[torch.Tensor]]]: A tuple containing the eigenvalues and their corresponding eigenvectors.</p> Source code in <code>src/landscaper/hessian.py</code> <pre><code>def eigenvalues(\n    self,\n    maxIter: int = 100,\n    tol: float = 1e-3,\n    top_n: int = 1,\n) -&gt; tuple[list[float], list[list[torch.Tensor]]]:\n    \"\"\"Computes the top_n eigenvalues using power iteration method.\n\n    Args:\n        maxIter (int, optional): Maximum iterations used to compute each single eigenvalue. Defaults to 100.\n        tol (float, optional): The relative tolerance between two consecutive eigenvalue computations\n            from power iteration. Defaults to 1e-3.\n        top_n (int, optional): The number of top eigenvalues to compute. Defaults to 1.\n\n    Returns:\n        tuple[list[float], list[list[torch.Tensor]]]: A tuple containing the eigenvalues and\n            their corresponding eigenvectors.\n    \"\"\"\n    assert top_n &gt;= 1 and not self.model.training\n    eigenvalues = []\n    eigenvectors = []\n\n    with tqdm(total=top_n, desc=\"Eigenvectors computed\", leave=True) as pbar:\n        computed_dim = 0\n\n        while computed_dim &lt; top_n:\n            eigenvalue = None\n            v = [torch.randn_like(p) for p in self.params]  # generate random vector\n\n            if self.use_complex:\n                v = [\n                    (\n                        torch.complex(vv, torch.randn_like(vv))\n                        if not torch.is_complex(vv)\n                        else vv\n                    )\n                    for vv in v\n                ]\n\n            v = normalization(v)  # normalize the vector\n\n            ibar = tqdm(\n                range(maxIter),\n                total=maxIter,\n                desc=\"Iteration\",\n                leave=False,\n                position=1,\n            )\n            for _ in ibar:\n                v = orthnormal(v, eigenvectors)\n\n                tmp_eigenvalue, Hv = self.hv_product(v)\n                v = normalization(Hv)\n\n                if eigenvalue is None:\n                    eigenvalue = tmp_eigenvalue\n                else:\n                    spec_gap = abs(eigenvalue - tmp_eigenvalue) / (\n                        abs(eigenvalue) + 1e-6\n                    )\n                    ibar.set_description(f\"Spectral gap: {spec_gap}\")\n                    if spec_gap &lt; tol:\n                        break\n                    else:\n                        eigenvalue = tmp_eigenvalue\n            eigenvalues.append(eigenvalue)\n            eigenvectors.append(v)\n            computed_dim += 1\n\n            pbar.update(1)\n\n    return eigenvalues, eigenvectors\n</code></pre>"},{"location":"reference/landscaper/hessian/#landscaper.hessian.PyHessian.hv_product","title":"<code>hv_product(v)</code>","text":"<p>Computes the product of the Hessian-vector product (Hv) for the data.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>list[Tensor]</code> <p>A list of tensors representing the vector to multiply with the Hessian.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[float, list[Tensor]]</code> <p>A tuple containing the eigenvalue (float) and the Hessian-vector product (list of tensors).</p> Source code in <code>src/landscaper/hessian.py</code> <pre><code>def hv_product(self, v: list[torch.Tensor]) -&gt; tuple[float, list[torch.Tensor]]:\n    \"\"\"Computes the product of the Hessian-vector product (Hv) for the data.\n\n    Args:\n        v (list[torch.Tensor]): A list of tensors representing the vector to multiply with the Hessian.\n\n    Returns:\n        tuple: A tuple containing the eigenvalue (float) and the Hessian-vector product (list of tensors).\n    \"\"\"\n    THv = [torch.zeros_like(p) for p in self.params]  # accumulate result\n\n    if self.use_complex:\n        THv = [\n            torch.complex(t, t.clone()) if not torch.is_complex(t) else t\n            for t in THv\n        ]\n\n    num_data = 0\n    for input_size, grads in self.gen(\n        self.model, self.criterion, self.data, self.device\n    ):\n        if self.use_complex:\n            grads = [\n                (\n                    torch.complex(g, torch.zeros_like(g))\n                    if not torch.is_complex(g)\n                    else g\n                )\n                for g in grads\n            ]\n\n        Hv = torch.autograd.grad(\n            grads,\n            self.params,\n            grad_outputs=v,\n            retain_graph=self.grad_cache is not None,\n        )\n\n        THv = [\n            THv1 + Hv1 * float(input_size) + 0.0\n            for THv1, Hv1 in zip(THv, Hv, strict=False)\n        ]\n        num_data += float(input_size)\n\n    THv = [THv1 / float(num_data) for THv1 in THv]\n    eigenvalue = group_product(THv, v).cpu().item()\n    return eigenvalue, THv\n</code></pre>"},{"location":"reference/landscaper/hessian/#landscaper.hessian.PyHessian.trace","title":"<code>trace(maxIter=100, tol=0.001)</code>","text":"<p>Computes the trace of the Hessian using Hutchinson's method.</p> <p>Parameters:</p> Name Type Description Default <code>maxIter</code> <code>int</code> <p>Maximum iterations used to compute the trace. Defaults to 100.</p> <code>100</code> <code>tol</code> <code>float</code> <p>The relative tolerance for convergence. Defaults to 1e-3.</p> <code>0.001</code> <p>Returns:</p> Type Description <code>list[float]</code> <p>list[float]: A list containing the trace of the Hessian computed over the iterations.</p> Source code in <code>src/landscaper/hessian.py</code> <pre><code>def trace(self, maxIter: int = 100, tol: float = 1e-3) -&gt; list[float]:\n    \"\"\"Computes the trace of the Hessian using Hutchinson's method.\n\n    Args:\n        maxIter (int): Maximum iterations used to compute the trace. Defaults to 100.\n        tol (float): The relative tolerance for convergence. Defaults to 1e-3.\n\n    Returns:\n        list[float]: A list containing the trace of the Hessian computed over the iterations.\n    \"\"\"\n    assert not self.model.training\n\n    trace_vhv = []\n    trace = 0.0\n\n    for _ in range(maxIter):\n        v = [torch.randint_like(p, high=2) for p in self.params]\n\n        if self.use_complex:\n            v = [\n                (\n                    torch.complex(vv, torch.randint_like(vv, high=2))\n                    if not torch.is_complex(vv)\n                    else vv\n                )\n                for vv in v\n            ]\n\n        # generate Rademacher random variables\n        for v_i in v:\n            v_i[v_i == 0] = -1\n        _, Hv = self.hv_product(v)\n        trace_vhv.append(group_product(Hv, v).cpu().item())\n        if abs(np.mean(trace_vhv) - trace) / (abs(trace) + 1e-6) &lt; tol:\n            return trace_vhv\n        else:\n            trace = np.mean(trace_vhv)\n\n    return trace_vhv\n</code></pre>"},{"location":"reference/landscaper/hessian/#landscaper.hessian.dimenet_generator","title":"<code>dimenet_generator(model, criterion, data, device)</code>","text":"<p>Calculates the per-sample gradient for DimeNet models.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The DimeNet model to calculate per-sample gradients for.</p> required <code>criterion</code> <code>Module</code> <p>Function that calculates the loss for the model.</p> required <code>data</code> <code>Any</code> <p>Source of data for the model.</p> required <code>device</code> <code>DeviceStr</code> <p>Device used for pyTorch calculations.</p> required <p>Yields:</p> Type Description <code>tuple[int, Tensor]</code> <p>The size of the current input (int) and the gradient.</p> Source code in <code>src/landscaper/hessian.py</code> <pre><code>def dimenet_generator(\n    model: torch.nn.Module,\n    criterion: torch.nn.Module | torch.Tensor,\n    data: Any,\n    device: DeviceStr,\n) -&gt; Generator[tuple[int, torch.Tensor], None, None]:\n    \"\"\"Calculates the per-sample gradient for DimeNet models.\n\n    Args:\n        model (torch.nn.Module): The DimeNet model to calculate per-sample gradients for.\n        criterion (torch.nn.Module): Function that calculates the loss for the model.\n        data (Any): Source of data for the model.\n        device (DeviceStr): Device used for pyTorch calculations.\n\n    Yields:\n        The size of the current input (int) and the gradient.\n    \"\"\"\n    params = [p for p in model.parameters() if p.requires_grad]\n\n    for batch in data:\n        input_size = len(batch)\n\n        # Move batch to the correct device\n        batch = batch.to(device)\n\n        # Compute loss using test_step which is consistent with how the model is used\n        loss = model.test_step(batch, 0, None)\n        grads = torch.autograd.grad(loss, params, create_graph=True)\n        yield input_size, grads\n</code></pre>"},{"location":"reference/landscaper/hessian/#landscaper.hessian.generic_generator","title":"<code>generic_generator(model, criterion, data, device)</code>","text":"<p>Calculates the per-sample gradient for the model.</p> <p>Default implementation used for PyHessian; the underlying code expects that this generator returns the size of the input and the gradient tensor at each step.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The model to calculate per-sample gradients for.</p> required <code>criterion</code> <code>Module</code> <p>Function that calculates the loss for the model.</p> required <code>data</code> <code>Any</code> <p>Source of data for the model.</p> required <code>device</code> <code>DeviceStr</code> <p>Device used for pyTorch calculations.</p> required <p>Yields:</p> Type Description <code>tuple[int, Tensor]</code> <p>The size of the current input (int) and the gradient for that sample.</p> Source code in <code>src/landscaper/hessian.py</code> <pre><code>def generic_generator(\n    model: torch.nn.Module,\n    criterion: torch.nn.Module,\n    data: Any,\n    device: DeviceStr,\n) -&gt; Generator[tuple[int, torch.Tensor], None, None]:\n    \"\"\"Calculates the per-sample gradient for the model.\n\n    Default implementation used for PyHessian; the underlying code expects that this generator\n    returns the size of the input and the gradient tensor at each step.\n\n    Args:\n        model (torch.nn.Module): The model to calculate per-sample gradients for.\n        criterion (torch.nn.Module): Function that calculates the loss for the model.\n        data (Any): Source of data for the model.\n        device (DeviceStr): Device used for pyTorch calculations.\n\n    Yields:\n        The size of the current input (int) and the gradient for that sample.\n    \"\"\"\n    params = [p for p in model.parameters() if p.requires_grad]\n\n    for sample, target in data:\n        outputs = model.forward(sample)\n        loss = criterion(outputs, target)\n\n        # instead of loss.backward we directly compute the gradient to avoid overwriting the gradient in place\n        grads = torch.autograd.grad(\n            loss, params, create_graph=True, materialize_grads=True\n        )\n        yield sample.size(0), grads\n</code></pre>"},{"location":"reference/landscaper/landscape/","title":"landscape","text":"<p>This module provides functions to compute the loss landscape of a model and visualize it in various ways.</p> <p>It includes methods for computing the loss landscape, loading it from a file, and visualizing it as a 3D surface, contour plot, or persistence barcode.</p>"},{"location":"reference/landscaper/landscape/#landscaper.landscape.LossLandscape","title":"<code>LossLandscape</code>","text":"<p>A class representing a loss landscape of a model.</p> <p>It contains methods to compute the landscape, visualize it, and analyze its topological properties.</p> Source code in <code>src/landscaper/landscape.py</code> <pre><code>class LossLandscape:\n    \"\"\"A class representing a loss landscape of a model.\n\n    It contains methods to compute the landscape, visualize it, and analyze its topological properties.\n    \"\"\"\n\n    @staticmethod\n    def compute(*args, **kwargs) -&gt; \"LossLandscape\":\n        \"\"\"Computes a loss landscape and directly creates a LossLandscape object.\n\n        See `landscaper.compute` for more information.\n\n        Returns:\n            (LossLandscape) A LossLandscape object.\n        \"\"\"\n        loss, coords = compute_loss_landscape(*args, **kwargs)\n        return LossLandscape(loss, coords)\n\n    @staticmethod\n    def load_from_npz(fp: str) -&gt; \"LossLandscape\":\n        \"\"\"Creates a LossLandscape object directly from an `.npz` file.\n\n        Args:\n            fp (str): path to the file.\n\n        Returns:\n            (LossLandscape) A LossLandscape object created from the file.\n        \"\"\"\n        loss, coords = load_landscape(fp)\n        return LossLandscape(loss, coords)\n\n    def __init__(self, loss: npt.ArrayLike, ranges: npt.ArrayLike) -&gt; None:\n        \"\"\"Initializes a LossLandscape object.\n\n        Args:\n            loss (npt.ArrayLike): A numpy array representing the loss values of the landscape.\n            ranges (npt.ArrayLike): A list of numpy arrays representing the ranges of each dimension of the landscape.\n\n        Raises:\n            ValueError: If the dimensions of the loss array do not match the number of coordinates.\n        \"\"\"\n        self.loss = loss\n        # converts meshgrid output of arbitrary dimensions into list of coordinates\n        grid = np.meshgrid(*ranges)\n        self.coords = np.array([list(z) for z in zip(*(x.flat for x in grid), strict=False)])\n\n        if self.coords.shape[0] != np.multiply.reduce(self.loss.shape):\n            raise ValueError(\n                f\"Loss dimensions do not match coordinate dimensions: Loss - {self.loss.shape}; \"\n                f\"Coordinates - {self.coords.shape}\"\n            )\n\n        self.ranges = ranges\n        self.dims = self.coords.shape[1]\n        self.graph = ngl.EmptyRegionGraph(beta=1.0, relaxed=False, p=2.0)\n        self.ms_complex = None\n        self.sub_tree = None\n        self.super_tree = None\n        self.topological_indices = None\n\n    def save(self, filename: str) -&gt; None:\n        \"\"\"Saves the loss and coordinates of the landscape to the specified path for later use.\n\n        Args:\n            filename (str): path to save the landscape to.\n        \"\"\"\n        np.savez(filename, loss=self.loss, coordinates=self.ranges)\n\n    def get_sublevel_tree(self) -&gt; tp.MergeTree:\n        \"\"\"Gets the merge tree corresponding to the minima of the loss landscape.\n\n        Returns:\n            A tp.MergeTree object corresponding to the minima of the loss landscape.\n        \"\"\"\n        if self.sub_tree is None:\n            self.sub_tree = merge_tree(self.loss, self.coords, self.graph)\n        return self.sub_tree\n\n    def get_super_tree(self) -&gt; tp.MergeTree:\n        \"\"\"Gets the merge tree corresponding to the maxima of the loss landscape.\n\n        Returns:\n            A tp.MergeTree object corresponding to the maxima of the loss landscape.\n        \"\"\"\n        if self.super_tree is None:\n            self.super_tree = merge_tree(self.loss, self.coords, self.graph, direction=-1)\n        return self.super_tree\n\n    def get_ms_complex(self) -&gt; tp.MorseSmaleComplex:\n        \"\"\"Gets the MorseSmaleComplex corresponding to the loss landscape.\n\n        Returns:\n            A tp.MorseSmaleComplex.\n        \"\"\"\n        if self.ms_complex is None:\n            ms_complex = tp.MorseSmaleComplex(graph=self.graph, gradient=\"steepest\", normalization=\"feature\")\n            ms_complex.build(np.array(self.coords), self.loss.flatten())\n            self.ms_complex = ms_complex\n        return self.ms_complex\n\n    def get_topological_indices(self) -&gt; dict[int, int]:\n        \"\"\"Returns a dictionary that maps point indices to their topological indices.\n\n        Returns:\n            (dict[int, int]): A dictionary mapping point indices to their topological indices.\n        \"\"\"\n        msc = self.get_ms_complex()\n        mt = self.get_sublevel_tree()\n        if self.topological_indices is None:\n            ti = {}\n            for n in mt.nodes:\n                ti[n] = topological_index(msc, n)\n            self.topological_indices = ti\n        return self.topological_indices\n\n    def get_persistence(self):\n        \"\"\"Returns the persistence of the landscape as a dictionary.\"\"\"\n        return get_persistence_dict(self.get_ms_complex())\n\n    def show(self, **kwargs):\n        \"\"\"Renders a 3D representation of the loss landscape.\n\n        See :obj:`landscaper.plots.surface_3d` for keyword arguments.\n\n        Raises:\n            ValueError: Thrown if the landscape has too many dimensions.\n        \"\"\"\n        if self.dims == 2:\n            return surface_3d(self.ranges, self.loss, **kwargs)\n        else:\n            raise ValueError(f\"Cannot visualize a landscape with {self.dims} dimensions.\")\n\n    def show_profile(self, **kwargs):\n        \"\"\"Renders the topological profile of the landscape.\n\n        See :obj:`landscaper.plots.topological_profile` for more details.\n        \"\"\"\n        mt = self.get_sublevel_tree()\n        profile = generate_profile(mt)\n        return topology_profile(profile, **kwargs)\n\n    def show_contour(self, **kwargs):\n        \"\"\"Renders a contour plot of the landscape.\n\n        See :obj:`landscaper.plots.contour` for more details.\n        \"\"\"\n        return contour(self.ranges, self.loss, **kwargs)\n\n    def show_persistence_barcode(self, **kwargs):\n        \"\"\"Renders the persistence barcode of the landscape.\n\n        See :obj:`landscaper.plots.persistence_barcode` for more details.\n        \"\"\"\n        msc = self.get_ms_complex()\n        return persistence_barcode(msc, **kwargs)\n\n    def smad(self) -&gt; float:\n        \"\"\"Calculates the Saddle-Minimum Average Distance (SMAD) for the landscape.\n\n        See our publication for more details.\n\n        Returns:\n            (float) A descriptor of the smoothness of the landscape.\n        \"\"\"\n        mt = self.get_sublevel_tree()\n        ti = self.get_topological_indices()\n\n        if len(mt.branches) == 0:\n            return 0.0\n\n        # branch persistence\n        bp = []\n        for b in mt.branches:\n            for edge in list(mt.edges):\n                n1, n2 = edge\n                if (b == n1 and ti[n2] == 0) or (b == n2 and ti[n1] == 0):\n                    bp.append(abs(mt.nodes[n1] - mt.nodes[n2]))\n        m = len(bp)\n\n        return sum(bp) / m\n</code></pre>"},{"location":"reference/landscaper/landscape/#landscaper.landscape.LossLandscape.__init__","title":"<code>__init__(loss, ranges)</code>","text":"<p>Initializes a LossLandscape object.</p> <p>Parameters:</p> Name Type Description Default <code>loss</code> <code>ArrayLike</code> <p>A numpy array representing the loss values of the landscape.</p> required <code>ranges</code> <code>ArrayLike</code> <p>A list of numpy arrays representing the ranges of each dimension of the landscape.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dimensions of the loss array do not match the number of coordinates.</p> Source code in <code>src/landscaper/landscape.py</code> <pre><code>def __init__(self, loss: npt.ArrayLike, ranges: npt.ArrayLike) -&gt; None:\n    \"\"\"Initializes a LossLandscape object.\n\n    Args:\n        loss (npt.ArrayLike): A numpy array representing the loss values of the landscape.\n        ranges (npt.ArrayLike): A list of numpy arrays representing the ranges of each dimension of the landscape.\n\n    Raises:\n        ValueError: If the dimensions of the loss array do not match the number of coordinates.\n    \"\"\"\n    self.loss = loss\n    # converts meshgrid output of arbitrary dimensions into list of coordinates\n    grid = np.meshgrid(*ranges)\n    self.coords = np.array([list(z) for z in zip(*(x.flat for x in grid), strict=False)])\n\n    if self.coords.shape[0] != np.multiply.reduce(self.loss.shape):\n        raise ValueError(\n            f\"Loss dimensions do not match coordinate dimensions: Loss - {self.loss.shape}; \"\n            f\"Coordinates - {self.coords.shape}\"\n        )\n\n    self.ranges = ranges\n    self.dims = self.coords.shape[1]\n    self.graph = ngl.EmptyRegionGraph(beta=1.0, relaxed=False, p=2.0)\n    self.ms_complex = None\n    self.sub_tree = None\n    self.super_tree = None\n    self.topological_indices = None\n</code></pre>"},{"location":"reference/landscaper/landscape/#landscaper.landscape.LossLandscape.compute","title":"<code>compute(*args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Computes a loss landscape and directly creates a LossLandscape object.</p> <p>See <code>landscaper.compute</code> for more information.</p> <p>Returns:</p> Type Description <code>LossLandscape</code> <p>(LossLandscape) A LossLandscape object.</p> Source code in <code>src/landscaper/landscape.py</code> <pre><code>@staticmethod\ndef compute(*args, **kwargs) -&gt; \"LossLandscape\":\n    \"\"\"Computes a loss landscape and directly creates a LossLandscape object.\n\n    See `landscaper.compute` for more information.\n\n    Returns:\n        (LossLandscape) A LossLandscape object.\n    \"\"\"\n    loss, coords = compute_loss_landscape(*args, **kwargs)\n    return LossLandscape(loss, coords)\n</code></pre>"},{"location":"reference/landscaper/landscape/#landscaper.landscape.LossLandscape.get_ms_complex","title":"<code>get_ms_complex()</code>","text":"<p>Gets the MorseSmaleComplex corresponding to the loss landscape.</p> <p>Returns:</p> Type Description <code>MorseSmaleComplex</code> <p>A tp.MorseSmaleComplex.</p> Source code in <code>src/landscaper/landscape.py</code> <pre><code>def get_ms_complex(self) -&gt; tp.MorseSmaleComplex:\n    \"\"\"Gets the MorseSmaleComplex corresponding to the loss landscape.\n\n    Returns:\n        A tp.MorseSmaleComplex.\n    \"\"\"\n    if self.ms_complex is None:\n        ms_complex = tp.MorseSmaleComplex(graph=self.graph, gradient=\"steepest\", normalization=\"feature\")\n        ms_complex.build(np.array(self.coords), self.loss.flatten())\n        self.ms_complex = ms_complex\n    return self.ms_complex\n</code></pre>"},{"location":"reference/landscaper/landscape/#landscaper.landscape.LossLandscape.get_persistence","title":"<code>get_persistence()</code>","text":"<p>Returns the persistence of the landscape as a dictionary.</p> Source code in <code>src/landscaper/landscape.py</code> <pre><code>def get_persistence(self):\n    \"\"\"Returns the persistence of the landscape as a dictionary.\"\"\"\n    return get_persistence_dict(self.get_ms_complex())\n</code></pre>"},{"location":"reference/landscaper/landscape/#landscaper.landscape.LossLandscape.get_sublevel_tree","title":"<code>get_sublevel_tree()</code>","text":"<p>Gets the merge tree corresponding to the minima of the loss landscape.</p> <p>Returns:</p> Type Description <code>MergeTree</code> <p>A tp.MergeTree object corresponding to the minima of the loss landscape.</p> Source code in <code>src/landscaper/landscape.py</code> <pre><code>def get_sublevel_tree(self) -&gt; tp.MergeTree:\n    \"\"\"Gets the merge tree corresponding to the minima of the loss landscape.\n\n    Returns:\n        A tp.MergeTree object corresponding to the minima of the loss landscape.\n    \"\"\"\n    if self.sub_tree is None:\n        self.sub_tree = merge_tree(self.loss, self.coords, self.graph)\n    return self.sub_tree\n</code></pre>"},{"location":"reference/landscaper/landscape/#landscaper.landscape.LossLandscape.get_super_tree","title":"<code>get_super_tree()</code>","text":"<p>Gets the merge tree corresponding to the maxima of the loss landscape.</p> <p>Returns:</p> Type Description <code>MergeTree</code> <p>A tp.MergeTree object corresponding to the maxima of the loss landscape.</p> Source code in <code>src/landscaper/landscape.py</code> <pre><code>def get_super_tree(self) -&gt; tp.MergeTree:\n    \"\"\"Gets the merge tree corresponding to the maxima of the loss landscape.\n\n    Returns:\n        A tp.MergeTree object corresponding to the maxima of the loss landscape.\n    \"\"\"\n    if self.super_tree is None:\n        self.super_tree = merge_tree(self.loss, self.coords, self.graph, direction=-1)\n    return self.super_tree\n</code></pre>"},{"location":"reference/landscaper/landscape/#landscaper.landscape.LossLandscape.get_topological_indices","title":"<code>get_topological_indices()</code>","text":"<p>Returns a dictionary that maps point indices to their topological indices.</p> <p>Returns:</p> Type Description <code>dict[int, int]</code> <p>A dictionary mapping point indices to their topological indices.</p> Source code in <code>src/landscaper/landscape.py</code> <pre><code>def get_topological_indices(self) -&gt; dict[int, int]:\n    \"\"\"Returns a dictionary that maps point indices to their topological indices.\n\n    Returns:\n        (dict[int, int]): A dictionary mapping point indices to their topological indices.\n    \"\"\"\n    msc = self.get_ms_complex()\n    mt = self.get_sublevel_tree()\n    if self.topological_indices is None:\n        ti = {}\n        for n in mt.nodes:\n            ti[n] = topological_index(msc, n)\n        self.topological_indices = ti\n    return self.topological_indices\n</code></pre>"},{"location":"reference/landscaper/landscape/#landscaper.landscape.LossLandscape.load_from_npz","title":"<code>load_from_npz(fp)</code>  <code>staticmethod</code>","text":"<p>Creates a LossLandscape object directly from an <code>.npz</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>fp</code> <code>str</code> <p>path to the file.</p> required <p>Returns:</p> Type Description <code>LossLandscape</code> <p>(LossLandscape) A LossLandscape object created from the file.</p> Source code in <code>src/landscaper/landscape.py</code> <pre><code>@staticmethod\ndef load_from_npz(fp: str) -&gt; \"LossLandscape\":\n    \"\"\"Creates a LossLandscape object directly from an `.npz` file.\n\n    Args:\n        fp (str): path to the file.\n\n    Returns:\n        (LossLandscape) A LossLandscape object created from the file.\n    \"\"\"\n    loss, coords = load_landscape(fp)\n    return LossLandscape(loss, coords)\n</code></pre>"},{"location":"reference/landscaper/landscape/#landscaper.landscape.LossLandscape.save","title":"<code>save(filename)</code>","text":"<p>Saves the loss and coordinates of the landscape to the specified path for later use.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>path to save the landscape to.</p> required Source code in <code>src/landscaper/landscape.py</code> <pre><code>def save(self, filename: str) -&gt; None:\n    \"\"\"Saves the loss and coordinates of the landscape to the specified path for later use.\n\n    Args:\n        filename (str): path to save the landscape to.\n    \"\"\"\n    np.savez(filename, loss=self.loss, coordinates=self.ranges)\n</code></pre>"},{"location":"reference/landscaper/landscape/#landscaper.landscape.LossLandscape.show","title":"<code>show(**kwargs)</code>","text":"<p>Renders a 3D representation of the loss landscape.</p> <p>See :obj:<code>landscaper.plots.surface_3d</code> for keyword arguments.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Thrown if the landscape has too many dimensions.</p> Source code in <code>src/landscaper/landscape.py</code> <pre><code>def show(self, **kwargs):\n    \"\"\"Renders a 3D representation of the loss landscape.\n\n    See :obj:`landscaper.plots.surface_3d` for keyword arguments.\n\n    Raises:\n        ValueError: Thrown if the landscape has too many dimensions.\n    \"\"\"\n    if self.dims == 2:\n        return surface_3d(self.ranges, self.loss, **kwargs)\n    else:\n        raise ValueError(f\"Cannot visualize a landscape with {self.dims} dimensions.\")\n</code></pre>"},{"location":"reference/landscaper/landscape/#landscaper.landscape.LossLandscape.show_contour","title":"<code>show_contour(**kwargs)</code>","text":"<p>Renders a contour plot of the landscape.</p> <p>See :obj:<code>landscaper.plots.contour</code> for more details.</p> Source code in <code>src/landscaper/landscape.py</code> <pre><code>def show_contour(self, **kwargs):\n    \"\"\"Renders a contour plot of the landscape.\n\n    See :obj:`landscaper.plots.contour` for more details.\n    \"\"\"\n    return contour(self.ranges, self.loss, **kwargs)\n</code></pre>"},{"location":"reference/landscaper/landscape/#landscaper.landscape.LossLandscape.show_persistence_barcode","title":"<code>show_persistence_barcode(**kwargs)</code>","text":"<p>Renders the persistence barcode of the landscape.</p> <p>See :obj:<code>landscaper.plots.persistence_barcode</code> for more details.</p> Source code in <code>src/landscaper/landscape.py</code> <pre><code>def show_persistence_barcode(self, **kwargs):\n    \"\"\"Renders the persistence barcode of the landscape.\n\n    See :obj:`landscaper.plots.persistence_barcode` for more details.\n    \"\"\"\n    msc = self.get_ms_complex()\n    return persistence_barcode(msc, **kwargs)\n</code></pre>"},{"location":"reference/landscaper/landscape/#landscaper.landscape.LossLandscape.show_profile","title":"<code>show_profile(**kwargs)</code>","text":"<p>Renders the topological profile of the landscape.</p> <p>See :obj:<code>landscaper.plots.topological_profile</code> for more details.</p> Source code in <code>src/landscaper/landscape.py</code> <pre><code>def show_profile(self, **kwargs):\n    \"\"\"Renders the topological profile of the landscape.\n\n    See :obj:`landscaper.plots.topological_profile` for more details.\n    \"\"\"\n    mt = self.get_sublevel_tree()\n    profile = generate_profile(mt)\n    return topology_profile(profile, **kwargs)\n</code></pre>"},{"location":"reference/landscaper/landscape/#landscaper.landscape.LossLandscape.smad","title":"<code>smad()</code>","text":"<p>Calculates the Saddle-Minimum Average Distance (SMAD) for the landscape.</p> <p>See our publication for more details.</p> <p>Returns:</p> Type Description <code>float</code> <p>(float) A descriptor of the smoothness of the landscape.</p> Source code in <code>src/landscaper/landscape.py</code> <pre><code>def smad(self) -&gt; float:\n    \"\"\"Calculates the Saddle-Minimum Average Distance (SMAD) for the landscape.\n\n    See our publication for more details.\n\n    Returns:\n        (float) A descriptor of the smoothness of the landscape.\n    \"\"\"\n    mt = self.get_sublevel_tree()\n    ti = self.get_topological_indices()\n\n    if len(mt.branches) == 0:\n        return 0.0\n\n    # branch persistence\n    bp = []\n    for b in mt.branches:\n        for edge in list(mt.edges):\n            n1, n2 = edge\n            if (b == n1 and ti[n2] == 0) or (b == n2 and ti[n1] == 0):\n                bp.append(abs(mt.nodes[n1] - mt.nodes[n2]))\n    m = len(bp)\n\n    return sum(bp) / m\n</code></pre>"},{"location":"reference/landscaper/plots/","title":"plots","text":"<p>Plots for visualizing topological data analysis results.</p> <p>TODO: get rid of plt.show calls so that users can pick between saving the figure &amp; displaying it interactively</p>"},{"location":"reference/landscaper/plots/#landscaper.plots.AxisOptions","title":"<code>AxisOptions</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Options for the Y axis of the topology profile.</p> <p>Attributes:</p> Name Type Description <code>tick_format</code> <code>Callable[[float], str]</code> <p>Function to format the tick labels.</p> <code>font_size</code> <code>int</code> <p>Font size for the tick labels.</p> Source code in <code>src/landscaper/plots.py</code> <pre><code>class AxisOptions(TypedDict):\n    \"\"\"Options for the Y axis of the topology profile.\n\n    Attributes:\n        tick_format (Callable[[float], str]): Function to format the tick labels.\n        font_size (int): Font size for the tick labels.\n    \"\"\"\n\n    tick_format: Callable[[float], str]\n    font_size: int\n</code></pre>"},{"location":"reference/landscaper/plots/#landscaper.plots.contour","title":"<code>contour(coordinates, loss, show=True, figsize=(12, 8))</code>","text":"<p>Draws a contour plot from the provided coordinates and values.</p> <p>Parameters:</p> Name Type Description Default <code>coordinates</code> <code>ArrayLike</code> <p>n-dimensional coordinates.</p> required <code>loss</code> <code>ArrayLike</code> <p>Value for each coordinate.</p> required <code>figsize</code> <code>tuple[int, int]</code> <p>Size of the figure.</p> <code>(12, 8)</code> <code>show</code> <code>bool</code> <p>If true, shows the plot; otherwise returns the figure.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>Raised if rendering fails.</p> Source code in <code>src/landscaper/plots.py</code> <pre><code>def contour(\n    coordinates: npt.ArrayLike,\n    loss: npt.ArrayLike,\n    show: bool = True,\n    figsize: tuple[int, int] = (12, 8),\n) -&gt; None | Figure:\n    \"\"\"Draws a contour plot from the provided coordinates and values.\n\n    Args:\n        coordinates (npt.ArrayLike): n-dimensional coordinates.\n        loss (npt.ArrayLike): Value for each coordinate.\n        figsize (tuple[int, int]): Size of the figure.\n        show (bool): If true, shows the plot; otherwise returns the figure.\n\n    Raises:\n        ValueError: Raised if rendering fails.\n    \"\"\"\n    fig = plt.figure(figsize=figsize)\n    ax1 = fig.add_subplot(111)\n    X, Y = np.meshgrid(coordinates[0], coordinates[1])\n\n    # Ensure all values are positive for log scale\n    min_loss = np.min(loss)\n    if min_loss &lt;= 0:\n        shift = -min_loss + 1e-6\n        loss = loss + shift\n        print(f\"Shifted loss surface by {shift} to ensure positive values\")\n\n    # Create logarithmically spaced levels\n    min_val = np.min(loss[loss &gt; 0])\n    max_val = np.max(loss)\n\n    if min_val &gt;= max_val:\n        raise ValueError(\"Invalid level range\")\n\n    try:\n        levels = np.logspace(np.log10(min_val), np.log10(max_val), 30)\n        # Create contour plot with log scale\n        contour_filled = ax1.contourf(\n            X,\n            Y,\n            loss,\n            levels=levels,\n            norm=LogNorm(vmin=min_val, vmax=max_val),\n            cmap=\"RdYlBu_r\",\n        )\n\n        contour_lines = ax1.contour(\n            X,\n            Y,\n            loss,\n            levels=levels[::3],\n            colors=\"black\",\n            linewidths=0.5,\n            alpha=0.5,\n        )\n        ax1.clabel(contour_lines, inline=True, fontsize=8, fmt=\"%.3f\")\n\n    except Exception as e:\n        print(f\"Warning: Log-scale contour plot failed ({e}). Using linear scale...\")\n        try:\n            # Try linear scale with fewer levels\n            levels = np.linspace(np.min(loss), np.max(loss), 20)\n            contour_filled = ax1.contourf(X, Y, loss, levels=levels, cmap=\"RdYlBu_r\")\n            contour_lines = ax1.contour(\n                X,\n                Y,\n                loss,\n                levels=levels[::2],\n                colors=\"black\",\n                linewidths=0.5,\n                alpha=0.5,\n            )\n            ax1.clabel(contour_lines, inline=True, fontsize=8, fmt=\"%.3f\")\n        except Exception as e:\n            print(f\"Warning: Linear scale plotting failed ({e}). Using pcolormesh...\")\n            contour_filled = ax1.pcolormesh(X, Y, loss, cmap=\"RdYlBu_r\", shading=\"auto\")\n\n    try:\n        plt.colorbar(contour_filled, ax=ax1, label=\"Loss\")\n    except Exception as e:\n        print(f\"Warning: Could not create colorbar: {e}\")\n\n    ax1.set_xlabel(\"Direction of First Eigenvector\", fontsize=12)\n    ax1.set_ylabel(\"Direction of Second Eigenvector\", fontsize=12)\n    ax1.set_title(\"Loss Landscape Contour\", fontsize=14)\n    ax1.grid(True, linestyle=\"--\", alpha=0.3)\n    ax1.axis(\"equal\")\n\n    if not show:\n        return fig\n    plt.show()\n</code></pre>"},{"location":"reference/landscaper/plots/#landscaper.plots.hessian_density","title":"<code>hessian_density(eigen, weight, show=True, figsize=(12, 6))</code>","text":"<p>Plots the density distribution of Hessian eigenvalues.</p> <p>Parameters:</p> Name Type Description Default <code>eigen</code> <code>ArrayLike</code> <p>Array of Hessian eigenvalues.</p> required <code>weight</code> <code>ArrayLike</code> <p>Corresponding weights for the eigenvalues.</p> required <code>show</code> <code>bool</code> <p>Shows the plot if true, otherwise returns the figure.</p> <code>True</code> <code>figsize</code> <code>tuple[int, int]</code> <p>Size of the figure.</p> <code>(12, 6)</code> Source code in <code>src/landscaper/plots.py</code> <pre><code>def hessian_density(eigen: npt.ArrayLike, weight: npt.ArrayLike, show: bool = True, figsize=(12, 6)) -&gt; None | Figure:\n    \"\"\"Plots the density distribution of Hessian eigenvalues.\n\n    Args:\n        eigen (npt.ArrayLike): Array of Hessian eigenvalues.\n        weight (npt.ArrayLike): Corresponding weights for the eigenvalues.\n        show (bool): Shows the plot if true, otherwise returns the figure.\n        figsize (tuple[int, int]): Size of the figure.\n    \"\"\"\n    density_eigen = np.array(eigen)\n    density_weight = np.array(weight)\n\n    # Ensure both arrays are 1D\n    if density_eigen.ndim &gt; 1:\n        density_eigen = density_eigen.ravel()\n    if density_weight.ndim &gt; 1:\n        density_weight = density_weight.ravel()\n\n    # Ensure arrays have matching dimensions\n    if len(density_eigen) != len(density_weight):\n        # Create new x points for interpolation\n        x_old = np.linspace(min(density_eigen), max(density_eigen), len(density_weight))\n        x_new = np.linspace(min(density_eigen), max(density_eigen), len(density_eigen))\n\n        f = interp1d(x_old, density_weight, kind=\"linear\", fill_value=\"extrapolate\")\n        density_weight = f(x_new)\n\n    # Ensure we're only plotting real components\n    if np.iscomplexobj(density_eigen):\n        density_eigen = density_eigen.real\n    if np.iscomplexobj(density_weight):\n        density_weight = density_weight.real\n\n    # Sort values for better visualization\n    sort_idx = np.argsort(density_eigen)\n    density_eigen = density_eigen[sort_idx]\n    density_weight = density_weight[sort_idx]\n\n    fig = plt.figure(figsize=figsize)\n    ax = fig.add_subplot(111)\n\n    # Create smooth curves using kernel density estimation\n    if len(density_eigen) &gt; 1:  # Only if we have enough points\n        # Separate positive and negative regions\n        pos_mask = density_eigen &gt;= 0\n        neg_mask = density_eigen &lt; 0\n\n        # Create histogram data with more bins for better resolution\n        num_bins = 200  # Increased from 100 to 200 for more detail\n\n        # Find the global min and max for consistent binning\n        global_min = min(density_eigen)\n        global_max = max(density_eigen)\n\n        # Create consistent bins across the entire range\n        bins = np.linspace(global_min, global_max, num_bins + 1)\n\n        # Create separate histograms but using the same bin definitions\n        pos_hist, _ = np.histogram(density_eigen[pos_mask], bins=bins, density=True)\n        neg_hist, _ = np.histogram(density_eigen[neg_mask], bins=bins, density=True)\n\n        # Plot histograms with consistent bins\n        ax.hist(\n            density_eigen[pos_mask],\n            bins=bins,\n            alpha=0.4,\n            color=\"#90CAF9\",\n            label=\"Positive Histogram\",\n            density=True,\n            edgecolor=\"#2E86C1\",\n            linewidth=0.5,\n        )\n        ax.hist(\n            density_eigen[neg_mask],\n            bins=bins,\n            alpha=0.4,\n            color=\"#FFAB91\",\n            label=\"Negative Histogram\",\n            density=True,\n            edgecolor=\"#E74C3C\",\n            linewidth=0.5,\n        )\n\n    ax.set_ylabel(\"Density\", fontsize=12, fontweight=\"bold\")\n    ax.set_xlabel(\"Eigenvalue\", fontsize=12, fontweight=\"bold\")\n    ax.set_title(\n        \"Hessian Eigenvalue Density Distribution\",\n        fontsize=14,\n        fontweight=\"bold\",\n        pad=15,\n    )\n\n    # Add vertical line at x=0\n    ax.axvline(x=0, color=\"black\", linestyle=\"--\", alpha=0.5)\n\n    # Add legend if we have both positive and negative values\n    if np.any(density_eigen &lt; 0) and np.any(density_eigen &gt;= 0):\n        ax.legend(loc=\"upper right\", frameon=True, fancybox=True, shadow=True)\n\n    ax.grid(True, linestyle=\"--\", alpha=0.7)\n    plt.tight_layout()\n\n    if not show:\n        return fig\n    plt.show()\n</code></pre>"},{"location":"reference/landscaper/plots/#landscaper.plots.hessian_eigenvalues","title":"<code>hessian_eigenvalues(top_eigenvalues, show=True, figsize=(12, 6))</code>","text":"<p>Plots the top-10 Hessian eigenvalues as an enhanced bar chart.</p> <p>Parameters:</p> Name Type Description Default <code>top_eigenvalues</code> <code>ArrayLike</code> <p>Array of top-10 Hessian eigenvalues.</p> required <code>show</code> <code>bool</code> <p>Shows the plot if true, otherwise returns the figure.</p> <code>True</code> <code>figsize</code> <code>tuple[int, int]</code> <p>Size of the figure.</p> <code>(12, 6)</code> Source code in <code>src/landscaper/plots.py</code> <pre><code>def hessian_eigenvalues(top_eigenvalues: npt.ArrayLike, show: bool = True, figsize=(12, 6)) -&gt; None | Figure:\n    \"\"\"Plots the top-10 Hessian eigenvalues as an enhanced bar chart.\n\n    Args:\n        top_eigenvalues (npt.ArrayLike): Array of top-10 Hessian eigenvalues.\n        show (bool): Shows the plot if true, otherwise returns the figure.\n        figsize (tuple[int, int]): Size of the figure.\n    \"\"\"\n    # Plot the top-10 eigenvalues as an enhanced bar chart\n    fig = plt.figure(figsize=figsize)\n    ax = fig.add_subplot(111)\n\n    indices = np.arange(len(top_eigenvalues))\n\n    # Create bars with different colors for positive and negative values\n    colors = [\"#2E86C1\" if val &gt;= 0 else \"#E74C3C\" for val in top_eigenvalues]\n    bars = ax.bar(indices, top_eigenvalues, color=colors, width=0.7)\n\n    # Add value labels on top of the bars\n    for bar in bars:\n        yval = bar.get_height()\n        ax.text(\n            bar.get_x() + bar.get_width() / 2,\n            yval + 0.01 * abs(yval),\n            f\"{yval:.3f}\",\n            ha=\"center\",\n            va=\"bottom\" if yval &gt;= 0 else \"top\",\n            fontsize=10,\n            fontweight=\"bold\",\n        )\n\n    plt.xlabel(\"Index\", fontsize=12, fontweight=\"bold\")\n    plt.ylabel(\"Eigenvalue\", fontsize=12, fontweight=\"bold\")\n    plt.title(\n        f\"Top-{len(top_eigenvalues)} Hessian Eigenvalues\",\n        fontsize=14,\n        fontweight=\"bold\",\n        pad=15,\n    )\n    # Improve x-axis ticks\n    ax.set_xticks(indices, [f\"{i + 1}\" for i in indices], fontsize=10)\n\n    # Add horizontal line at y=0 with better styling\n    ax.axhline(y=0, color=\"black\", linestyle=\"-\", alpha=0.2, zorder=0)\n\n    # Add grid with better styling\n    ax.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.3, zorder=0)\n\n    legend_elements = [\n        Patch(facecolor=\"#2E86C1\", label=\"Positive Eigenvalues\", alpha=0.9),\n        Patch(facecolor=\"#E74C3C\", label=\"Negative Eigenvalues\", alpha=0.9),\n    ]\n    ax.legend(\n        handles=legend_elements,\n        loc=\"upper right\",\n        frameon=True,\n        fancybox=True,\n        shadow=True,\n    )\n\n    # Adjust layout\n    plt.tight_layout()\n    if not show:\n        return fig\n    plt.show()\n</code></pre>"},{"location":"reference/landscaper/plots/#landscaper.plots.linearScale","title":"<code>linearScale(min_val, max_val, new_min, new_max)</code>","text":"<p>Creates a linear scale that maps [min_val, max_val] -&gt; [new_min, new_max]; similar to d3's <code>linearScale</code>.</p> <p>Parameters:</p> Name Type Description Default <code>min_val</code> <code>int | float</code> <p>Current min value.</p> required <code>max_val</code> <code>int | float</code> <p>Current max value.</p> required <code>new_min</code> <code>int | float</code> <p>Desired min value.</p> required <code>new_max</code> <code>int | float</code> <p>Desired max value.</p> required <p>Returns:</p> Type Description <code>Callable[[Number], Number]</code> <p>A function to convert values from the old range to the new one.</p> Source code in <code>src/landscaper/plots.py</code> <pre><code>def linearScale(min_val: Number, max_val: Number, new_min: Number, new_max: Number) -&gt; Callable[[Number], Number]:\n    \"\"\"Creates a linear scale that maps [min_val, max_val] -&gt; [new_min, new_max]; similar to d3's `linearScale`.\n\n    Args:\n        min_val (int | float): Current min value.\n        max_val (int | float): Current max value.\n        new_min (int | float): Desired min value.\n        new_max (int | float): Desired max value.\n\n    Returns:\n        A function to convert values from the old range to the new one.\n    \"\"\"\n    return lambda x: (new_max - new_min) / (max_val - min_val) * (x - max_val) + new_max\n</code></pre>"},{"location":"reference/landscaper/plots/#landscaper.plots.persistence_barcode","title":"<code>persistence_barcode(msc, show=True, figsize=(12, 6))</code>","text":"<p>Plots the persistence barcode  for a Morse-Smale complex.</p> <p>Parameters:</p> Name Type Description Default <code>msc</code> <code>MorseSmaleComplex</code> <p>A Morse-Smale complex.</p> required <code>show</code> <code>bool</code> <p>Shows the plot if true, otherwise returns the figure.</p> <code>True</code> <code>figsize</code> <code>tuple[int, int]</code> <p>Size of the figure.</p> <code>(12, 6)</code> Source code in <code>src/landscaper/plots.py</code> <pre><code>def persistence_barcode(\n    msc: tp.MorseSmaleComplex, show: bool = True, figsize: tuple[int, int] = (12, 6)\n) -&gt; None | Figure:\n    \"\"\"Plots the [persistence barcode](https://en.wikipedia.org/wiki/Persistence_barcode)  for a Morse-Smale complex.\n\n    Args:\n        msc (tp.MorseSmaleComplex): A Morse-Smale complex.\n        show (bool): Shows the plot if true, otherwise returns the figure.\n        figsize (tuple[int,int]): Size of the figure.\n    \"\"\"\n    fig = plt.figure(figsize=figsize)\n    ax = fig.add_subplot(111)\n    node_list = [str(node) for node in list(get_persistence_dict(msc).keys())]\n    persistence_list = list(get_persistence_dict(msc).values())\n    ax.barh(node_list, persistence_list)\n    ax.set_xlabel(\"Persistence\")\n    ax.set_ylabel(\"Node\")\n    ax.set_title(\"Node vs Persistence\")\n\n    if not show:\n        return fig\n    plt.show()\n</code></pre>"},{"location":"reference/landscaper/plots/#landscaper.plots.surface_3d","title":"<code>surface_3d(coords, loss, show=True, figsize=(12, 8))</code>","text":"<p>Generates a 3d surface plot for the given coordinates and values. Fails if dimensions are greater than 2.</p> <p>Parameters:</p> Name Type Description Default <code>coords</code> <code>ArrayLike</code> <p>2-D coordinates.</p> required <code>loss</code> <code>ArrayLike</code> <p>Values for the coordinates.</p> required <code>show</code> <code>bool</code> <p>Shows the plot if true, otherwise returns the figure.</p> <code>True</code> <code>figsize</code> <code>tuple[int, int]</code> <p>Size of the figure.</p> <code>(12, 8)</code> Source code in <code>src/landscaper/plots.py</code> <pre><code>def surface_3d(\n    coords: npt.ArrayLike,\n    loss: npt.ArrayLike,\n    show: bool = True,\n    figsize: tuple[int, int] = (12, 8),\n) -&gt; None | Figure:\n    \"\"\"Generates a 3d surface plot for the given coordinates and values. Fails if dimensions are greater than 2.\n\n    Args:\n        coords (npt.ArrayLike): 2-D coordinates.\n        loss (npt.ArrayLike): Values for the coordinates.\n        show (bool): Shows the plot if true, otherwise returns the figure.\n        figsize (tuple[int,int]): Size of the figure.\n    \"\"\"\n    # Create 3D surface plot\n    fig = plt.figure(figsize=figsize)\n    ax = fig.add_subplot(111, projection=\"3d\")\n    X, Y = np.meshgrid(coords[0], coords[1])\n\n    min_val = np.min(loss[loss &gt; 0])\n    max_val = np.max(loss)\n\n    try:\n        # Try log-scale surface plot\n        print(\"Attempting log-scale surface plot...\")\n        norm = LogNorm(vmin=min_val, vmax=max_val)\n        surf = ax.plot_surface(\n            X,\n            Y,\n            loss,\n            cmap=\"RdYlBu_r\",\n            norm=norm,\n            linewidth=0,\n            antialiased=True,\n        )\n        plt.colorbar(surf, label=\"Loss (log scale)\")\n    except Exception as e:\n        print(f\"Warning: Log-scale 3D plotting failed ({e}). Using linear scale...\")\n        surf = ax.plot_surface(X, Y, loss, cmap=\"RdYlBu_r\", linewidth=0, antialiased=True)\n        plt.colorbar(surf, label=\"Loss\")\n\n    ax.set_xlabel(\"Direction of First Eigenvector\")\n    ax.set_ylabel(\"Direction of Second Eigenvector\")\n    ax.set_zlabel(\"Loss\")\n    ax.set_title(\"3D Loss Landscape\")\n\n    # Adjust the viewing angle for better visualization\n    ax.view_init(elev=30, azim=45)\n\n    if not show:\n        return fig\n    plt.show()\n</code></pre>"},{"location":"reference/landscaper/plots/#landscaper.plots.topology_profile","title":"<code>topology_profile(data, y_min=None, y_max=None, size=800, margin=15, color='red', background_color='white', gradient=True, y_axis=default_axis)</code>","text":"<p>Renders a topological profile.</p> <p>Renders a topological profile for the given merge tree data extracted with <code>extract_merge_tree</code> from <code>landscaper.tda</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[List[float]]</code> <p>The merge tree data.</p> required <code>y_min</code> <code>Optional[float]</code> <p>Optional minimum y value for the drawing.</p> <code>None</code> <code>y_max</code> <code>Optional[float]</code> <p>Optional maximum y value for the drawing.</p> <code>None</code> <code>size</code> <code>int</code> <p>Size in pixels of the resulting drawing.</p> <code>800</code> <code>margin</code> <code>int</code> <p>Size of the margins in pixels.</p> <code>15</code> <code>color</code> <code>str</code> <p>Color used to draw the profile.</p> <code>'red'</code> <code>background_color</code> <code>str</code> <p>Color used to draw the background.</p> <code>'white'</code> <code>gradient</code> <code>bool</code> <p>If true, fills the profile using a gradient from <code>background_color</code> to <code>color</code>. If false, only uses <code>color</code> to fill the path. Set this to false if you are exporting the drawing into a different format.</p> <code>True</code> <code>y_axis</code> <code>AxisOptions</code> <p>Sets options for the Y axis. Set to None to disable.</p> <code>default_axis</code> Source code in <code>src/landscaper/plots.py</code> <pre><code>def topology_profile(\n    data,\n    y_min: float | None = None,\n    y_max: float | None = None,\n    size: int = 800,\n    margin: int = 15,\n    color: str = \"red\",\n    background_color: str = \"white\",\n    gradient: bool = True,\n    y_axis: AxisOptions | None = default_axis,\n) -&gt; dw.Drawing:\n    \"\"\"Renders a topological profile.\n\n    Renders a topological profile for the given merge tree data\n    extracted with `extract_merge_tree` from `landscaper.tda`.\n\n    Args:\n        data (List[List[float]]): The merge tree data.\n        y_min (Optional[float]): Optional minimum y value for the drawing.\n        y_max (Optional[float]): Optional maximum y value for the drawing.\n        size (int): Size in pixels of the resulting drawing.\n        margin (int): Size of the margins in pixels.\n        color (str): Color used to draw the profile.\n        background_color (str): Color used to draw the background.\n        gradient (bool): If true, fills the profile using a gradient from `background_color` to `color`.\n            If false, only uses `color` to fill the path. Set this to false if you are\n            exporting the drawing into a different format.\n        y_axis (AxisOptions): Sets options for the Y axis. Set to None to disable.\n    \"\"\"\n    # TODO: validate profile data\n    width = size\n    height = size\n    marginTop = margin\n    marginRight = margin\n    marginBottom = margin\n    marginLeft = margin\n\n    loss_max = float(\"-inf\")\n    loss_min = float(\"inf\")\n    x_max = float(\"-inf\")\n    x_min = float(\"inf\")\n\n    # data should be a list of lists\n    for d in data:\n        xVals = [pt[0] for pt in d]\n        yVals = [pt[1] for pt in d]\n\n        x_max = max(x_max, max(xVals))\n        x_min = min(x_min, min(xVals))\n        loss_max = max(loss_max, max(yVals))\n        loss_min = min(loss_min, min(yVals))\n\n    # keep colors consistent regardless of y min and max chosen\n    basinColors = Color.interpolate(\n        [color, background_color],\n        domain=[max(loss_min, 1e-10), loss_max],\n    )\n\n    if y_max is not None:\n        loss_max = y_max\n\n    if y_min is not None:\n        loss_min = y_min\n\n    xScale = linearScale(x_min, x_max, marginLeft, width - marginRight)\n    yScale = linearScale(loss_min, loss_max, height - marginBottom, marginTop)\n\n    svg = dw.Drawing(width, height)\n    svg.append(dw.Rectangle(0, 0, width, height, fill=\"white\", stroke=\"#777\"))  # background color\n\n    for d in data:\n        yVals = [pt[1] for pt in d]\n        minY = min(yVals)\n        maxY = max(yVals)\n\n        if gradient:\n            grad = dw.LinearGradient(\"0%\", \"100%\", \"0%\", \"0%\", gradientUnits=\"objectBoundingBox\")\n\n            for t in np.linspace(0.0, 1.0, 100):\n                yValue = minY + t * (maxY - minY)\n                grad.add_stop(f\"{t * 100}%\", basinColors(yValue).to_string(hex=True, upper=True))\n        else:\n            grad = color\n\n        path = dw.Path(stroke=grad, fill=grad)\n        start, *pts = d\n        sx, sy = start\n        path.M(xScale(sx), yScale(sy))\n        for pt in pts:\n            x, y = pt\n            path.L(xScale(x), yScale(y))\n        svg.append(path)\n\n    if y_axis is not None:\n        ax = dw.Line(\n            marginLeft / 2,\n            height - marginBottom,\n            marginLeft / 2,\n            marginTop,\n            stroke=\"black\",\n        )\n\n        svg.append(ax)\n        for t in np.linspace(0.0, 1.0, 10):\n            v = loss_min + t * (loss_max - loss_min)\n            tv = yScale(v)\n            tick = dw.Line(marginLeft / 2, tv, marginLeft, tv, stroke=\"black\")\n            lbl = dw.Text(\n                y_axis[\"tick_format\"](v),\n                font_size=y_axis[\"font_size\"],\n                dominant_baseline=\"middle\",\n                x=marginLeft,\n                y=tv,\n            )\n            svg.append(lbl)\n            svg.append(tick)\n\n    return svg\n</code></pre>"},{"location":"reference/landscaper/tda/","title":"tda","text":"<p>This module contains for topological data analysis (TDA) of loss landscapes.</p>"},{"location":"reference/landscaper/tda/#landscaper.tda.bottleneck_distance","title":"<code>bottleneck_distance(p1, p2)</code>","text":"<p>Calculates the bottleneck distance between two persistence diagrams.</p> <p>Parameters:</p> Name Type Description Default <code>p1</code> <code>ArrayLike</code> <p>The first persistence diagram, represented as a 1D array of persistence values.</p> required <code>p2</code> <code>ArrayLike</code> <p>The second persistence diagram, represented as a 1D array of persistence values.</p> required <p>Returns:</p> Type Description <code>float</code> <p>A float representing the bottleneck distance between the two diagrams.</p> Source code in <code>src/landscaper/tda.py</code> <pre><code>def bottleneck_distance(p1: npt.ArrayLike, p2: npt.ArrayLike) -&gt; float:\n    \"\"\"Calculates the bottleneck distance between two persistence diagrams.\n\n    Args:\n        p1 (npt.ArrayLike): The first persistence diagram, represented as a 1D array of persistence values.\n        p2 (npt.ArrayLike): The second persistence diagram, represented as a 1D array of persistence values.\n\n    Returns:\n            A float representing the bottleneck distance between the two diagrams.\n    \"\"\"\n    ppd1 = [(0, val) for val in p1]\n    ppd2 = [(0, val) for val in p2]\n    return gd.bottleneck_distance(ppd1, ppd2)\n</code></pre>"},{"location":"reference/landscaper/tda/#landscaper.tda.digraph_mt","title":"<code>digraph_mt(mt)</code>","text":"<p>Converts a merge tree to a directed graph representation that makes it easy to navigate the hierarchy.</p> <p>The root is the maximum which points down the tree towards saddles and minima. The 'partition' edge attributes list the members of the integral line from node a-&gt;b, while 'counts' contains the number of members along that line.</p> <p>Parameters:</p> Name Type Description Default <code>mt</code> <code>MergeTree</code> <p>The merge tree to convert.</p> required <p>Returns:</p> Type Description <code>DiGraph</code> <p>A networkx DiGraph representation of the merge tree hierarchy.</p> Source code in <code>src/landscaper/tda.py</code> <pre><code>def digraph_mt(mt: tp.MergeTree) -&gt; nx.DiGraph:\n    \"\"\"Converts a merge tree to a directed graph representation that makes it easy to navigate the hierarchy.\n\n    The root is the maximum which points down the tree towards saddles and minima.\n    The 'partition' edge attributes list the members of the integral line from node a-&gt;b,\n    while 'counts' contains the number of members along that line.\n\n    Args:\n        mt (tp.MergeTree): The merge tree to convert.\n\n    Returns:\n        A networkx DiGraph representation of the merge tree hierarchy.\n    \"\"\"\n    g = nx.DiGraph()\n    for n, v in mt.nodes.items():\n        g.add_node(n, value=v)\n\n    g.add_edges_from([(e[1], e[0]) for e in list(mt.edges)])\n    e_info = {(e[1], e[0]): [e[0]] for e in list(mt.edges)}\n    aug_info = {(e[1], e[0]): [e[0], *v] for e, v in mt.augmentedEdges.items()}\n    e_info.update(aug_info)\n\n    nx.set_edge_attributes(g, e_info, \"partitions\")\n    len_part_dict = {e: len(v) for e, v in e_info.items()}\n    nx.set_edge_attributes(g, len_part_dict, \"counts\")\n\n    return g\n</code></pre>"},{"location":"reference/landscaper/tda/#landscaper.tda.get_persistence_dict","title":"<code>get_persistence_dict(msc)</code>","text":"<p>Returns the persistence of the given Morse-Smale complex as a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>msc</code> <code>MorseSmaleComplex</code> <p>A Morse-Smale complex from Topopy.</p> required <p>Returns:</p> Type Description <p>The values of the Morse-Smale Complex as a dictionary of nodes to persistence values.</p> Source code in <code>src/landscaper/tda.py</code> <pre><code>def get_persistence_dict(msc: tp.MorseSmaleComplex):\n    \"\"\"Returns the persistence of the given Morse-Smale complex as a dictionary.\n\n    Args:\n        msc (tp.MorseSmaleComplex): A Morse-Smale complex from [Topopy](https://github.com/maljovec/topopy).\n\n    Returns:\n        The values of the Morse-Smale Complex as a dictionary of nodes to persistence values.\n    \"\"\"\n    \"\"\"\"\"\"\n    return {key: msc.get_merge_sequence()[key][0] for key in msc.get_merge_sequence()}\n</code></pre>"},{"location":"reference/landscaper/tda/#landscaper.tda.merge_tree","title":"<code>merge_tree(loss, coords, graph, direction=1)</code>","text":"<p>Helper function used to generate a merge tree for a loss landscape.</p> <p>Parameters:</p> Name Type Description Default <code>loss</code> <code>ArrayLike</code> <p>Function values for each point in the space.</p> required <code>coords</code> <code>ArrayLike</code> <p>N-dimensional array of ranges for each dimension in the space.</p> required <code>graph</code> <code>nglGraph</code> <p>nglpy graph of the space (usually filled out by topopy).</p> required <code>direction</code> <code>Literal[-1, 1]</code> <p>The direction to generate a merge tree for. -1 generates a merge tree for maxima, while the default value (1) is for minima.</p> <code>1</code> <p>Returns:</p> Type Description <code>MergeTree</code> <p>Merge tree for the space.</p> Source code in <code>src/landscaper/tda.py</code> <pre><code>def merge_tree(\n    loss: npt.ArrayLike,\n    coords: npt.ArrayLike,\n    graph: ngl.EmptyRegionGraph,\n    direction: Literal[-1, 1] = 1,\n) -&gt; tp.MergeTree:\n    \"\"\"Helper function used to generate a merge tree for a loss landscape.\n\n    Args:\n        loss (np.ArrayLike): Function values for each point in the space.\n        coords (np.ArrayLike): N-dimensional array of ranges for each dimension in the space.\n        graph (ngl.nglGraph): nglpy graph of the space (usually filled out by topopy).\n        direction (Literal[-1,1]): The direction to generate a merge tree for.\n            -1 generates a merge tree for maxima, while the default value (1) is for minima.\n\n    Returns:\n        Merge tree for the space.\n    \"\"\"\n    loss_flat = loss.flatten()\n    t = tp.MergeTree(graph=graph)\n    t.build(np.array(coords), direction * loss_flat)\n    return t\n</code></pre>"},{"location":"reference/landscaper/tda/#landscaper.tda.merge_tree_to_nx","title":"<code>merge_tree_to_nx(mt)</code>","text":"<p>Converts a Topopy MergeTree to a networkx representation.</p> <p>Parameters:</p> Name Type Description Default <code>mt</code> <code>MergeTree</code> <p>The merge tree to convert.</p> required <p>Returns:</p> Type Description <code>Graph</code> <p>A networkx Graph representation of the merge tree. Can be used for visualization and analysis.</p> Source code in <code>src/landscaper/tda.py</code> <pre><code>def merge_tree_to_nx(mt: tp.MergeTree) -&gt; nx.Graph:\n    \"\"\"Converts a Topopy MergeTree to a networkx representation.\n\n    Args:\n        mt (tp.MergeTree): The merge tree to convert.\n\n    Returns:\n       A networkx Graph representation of the merge tree. Can be used for visualization and analysis.\n    \"\"\"\n    g = nx.Graph()\n    for n, v in mt.nodes.items():\n        g.add_node(n, value=v)\n    g.add_edges_from(list(mt.edges))\n    return g\n</code></pre>"},{"location":"reference/landscaper/tda/#landscaper.tda.topological_index","title":"<code>topological_index(msc, idx)</code>","text":"<p>Gets the topological index of a given point.</p> <p>Parameters:</p> Name Type Description Default <code>msc</code> <code>MorseSmaleComplex</code> <p>The Morse-Smale complex that represents the space being analyzed.</p> required <code>idx</code> <code>int</code> <p>The index of the point to get a topological index for.</p> required <p>Returns:</p> Type Description <code>Literal[0, 1, 2]</code> <p>Either 0, 1, or 2. This indicates that the point is either a minima (0), saddle point (1) or a maxima (2).</p> Source code in <code>src/landscaper/tda.py</code> <pre><code>def topological_index(msc: tp.MorseSmaleComplex, idx: int) -&gt; Literal[0, 1, 2]:\n    \"\"\"Gets the topological index of a given point.\n\n    Args:\n        msc (tp.MorseSmaleComplex): The Morse-Smale complex that represents the space being analyzed.\n        idx (int): The index of the point to get a topological index for.\n\n    Returns:\n        Either 0, 1, or 2. This indicates that the point is either a minima (0), saddle point (1) or a maxima (2).\n    \"\"\"\n    c = msc.get_classification(idx)\n    if c == \"minimum\":\n        return 0\n    elif c == \"regular\":\n        return 1\n    else:\n        return 2\n</code></pre>"},{"location":"reference/landscaper/topology_profile/","title":"topology_profile","text":"<p>Function to generate topological profiles from a merge tree.</p>"},{"location":"reference/landscaper/topology_profile/#landscaper.topology_profile.assign_center","title":"<code>assign_center(node_id, g, start, end)</code>","text":"<p>Assigns the center of the basin when constructing the profile. Needed for visualization.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>int</code> <p>Node ID.</p> required <code>g</code> <code>DiGraph</code> <p>Directed graph representation of a merge tree.</p> required <code>start</code> <code>int</code> <p>Leftmost point.</p> required <code>end</code> <code>int</code> <p>Rightmost point.</p> required Source code in <code>src/landscaper/topology_profile.py</code> <pre><code>def assign_center(node_id: int, g: nx.DiGraph, start: int, end: int) -&gt; None:\n    \"\"\"Assigns the center of the basin when constructing the profile. Needed for visualization.\n\n    Args:\n        node_id (int): Node ID.\n        g (nx.DiGraph): Directed graph representation of a merge tree.\n        start (int): Leftmost point.\n        end (int): Rightmost point.\n    \"\"\"\n    node = g.nodes[node_id]\n    center = (start + end) / 2\n    node[\"center\"] = center\n\n    children = list(g.successors(node_id))\n    if len(children) == 0:\n        return\n\n    cw = node[\"child_width\"]\n    left = start + (end - start) / 2 - cw / 2\n    children = sorted(children, key=lambda x: g.nodes[x][\"total_width\"], reverse=True)\n    for child in children:\n        proportion = g.nodes[child][\"total_width\"] / cw\n        partial_length = cw * proportion\n        assign_center(child, g, left, left + partial_length)\n        left += partial_length\n</code></pre>"},{"location":"reference/landscaper/topology_profile/#landscaper.topology_profile.build_basin","title":"<code>build_basin(node_id, g, mt)</code>","text":"<p>Recursively calculates the points needed for each segmentation in the merge tree.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>int</code> <p>Node ID to calculate a basin for.</p> required <code>g</code> <code>DiGraph</code> <p>Directed graph representation of the merge tree.</p> required <code>mt</code> <code>MergeTree</code> <p>The merge tree.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Total width of a given basin.</p> Source code in <code>src/landscaper/topology_profile.py</code> <pre><code>def build_basin(node_id: int, g: nx.DiGraph, mt: tp.MergeTree) -&gt; int:\n    \"\"\"Recursively calculates the points needed for each segmentation in the merge tree.\n\n    Args:\n        node_id (int): Node ID to calculate a basin for.\n        g (nx.DiGraph): Directed graph representation of the merge tree.\n        mt (tp.MergeTree): The merge tree.\n\n    Returns:\n        Total width of a given basin.\n    \"\"\"\n    child_width = 0\n    for child_id in g.successors(node_id):\n        child_width += build_basin(child_id, g, mt)\n\n    reachable = list(nx.bfs_edges(g, node_id))\n    parts = nx.get_edge_attributes(g, \"partitions\")\n\n    vals = list(itertools.chain.from_iterable([parts[e] for e in reachable]))\n    segmentations = [mt.Y[v] for v in vals]\n    segmentations.sort()\n\n    parent = get_parent(g, node_id)\n    if parent is not None:\n        segmentations.append(g.nodes[parent][\"value\"])\n\n    nx.set_node_attributes(\n        g,\n        {\n            node_id: {\n                \"points\": segmentations,\n                \"total_width\": len(segmentations),\n                \"child_width\": child_width,\n            }\n        },\n    )\n    return len(segmentations)\n</code></pre>"},{"location":"reference/landscaper/topology_profile/#landscaper.topology_profile.generate_profile","title":"<code>generate_profile(mt)</code>","text":"<p>Generates a topological profile based on a merge tree.</p> <p>Used along with :obj:<code>landscaper.plots.topoplogy_profile</code>. Can be visualized directly with a LossLandscape object using :obj:<code>landscaper.landscape.LossLandscape.show_profile</code>.</p> <p>Parameters:</p> Name Type Description Default <code>mt</code> <code>MergeTree</code> <p>The merge tree to generate a profile for.</p> required <p>Returns:</p> Type Description <code>list[list[list[float]]]</code> <p>Profile data to visualize.</p> Source code in <code>src/landscaper/topology_profile.py</code> <pre><code>def generate_profile(mt: tp.MergeTree) -&gt; list[list[list[float]]]:\n    \"\"\"Generates a topological profile based on a merge tree.\n\n    Used along with :obj:`landscaper.plots.topoplogy_profile`. Can be visualized\n    directly with a LossLandscape object using :obj:`landscaper.landscape.LossLandscape.show_profile`.\n\n    Args:\n        mt (tp.MergeTree): The merge tree to generate a profile for.\n\n    Returns:\n        Profile data to visualize.\n    \"\"\"\n    root = mt.root\n\n    g = digraph_mt(mt)\n    build_basin(root, g, mt)\n    assign_center(root, g, 0, g.nodes[root][\"total_width\"])\n\n    # Initialize result arrays\n    res = []\n\n    def _collect_individual_basins(node_id):\n        node = g.nodes[node_id]\n        for child in g.successors(node_id):\n            _collect_individual_basins(child)\n\n        right = [[i + node[\"center\"], y] for i, y in enumerate(node[\"points\"])]\n\n        node[\"points\"].reverse()\n        left = [[-1 * (len(node[\"points\"]) - i) + node[\"center\"], y] for i, y in enumerate(node[\"points\"])]\n\n        pts = left + right\n        if len(pts) &gt; 0:\n            res.append(\n                pts,\n            )\n\n    _collect_individual_basins(root)\n\n    return res\n</code></pre>"},{"location":"reference/landscaper/topology_profile/#landscaper.topology_profile.get_parent","title":"<code>get_parent(g, n)</code>","text":"<p>Gets the parent of a node in the directed graph. Errors if there is more than one parent (no longer a tree).</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>DiGraph</code> <p>Directed graph representation of a merge tree.</p> required <code>n</code> <code>int</code> <p>Node ID to get parent for.</p> required <p>Returns:</p> Type Description <code>int | None</code> <p>The node id of the parent.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Thrown when there is more than one parent for a node.</p> Source code in <code>src/landscaper/topology_profile.py</code> <pre><code>def get_parent(g: nx.DiGraph, n: int) -&gt; int | None:\n    \"\"\"Gets the parent of a node in the directed graph. Errors if there is more than one parent (no longer a tree).\n\n    Args:\n        g (nx.DiGraph): Directed graph representation of a merge tree.\n        n (int): Node ID to get parent for.\n\n    Returns:\n        The node id of the parent.\n\n    Raises:\n        ValueError: Thrown when there is more than one parent for a node.\n    \"\"\"\n    pred = list(g.predecessors(n))\n    if len(pred) == 0:\n        return None\n    elif len(pred) &gt; 1:\n        raise ValueError(\"Graph has nodes with more than 1 parent!\")\n    else:\n        return pred[0]\n</code></pre>"},{"location":"reference/landscaper/utils/","title":"utils","text":"<p>Utility functions for the Landscaper package.</p>"},{"location":"reference/landscaper/utils/#landscaper.utils.generate_random_orthogonal_directions","title":"<code>generate_random_orthogonal_directions(model, n=3)</code>","text":"<p>Generates n random orthogonal directions in the parameter space of the model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The model for which to generate directions.</p> required <code>n</code> <code>int</code> <p>Number of orthogonal directions to generate. Defaults to 3.</p> <code>3</code> <p>Returns:</p> Type Description <code>list[list[Tensor]]</code> <p>list[list[torch.Tensor]]: A list of n lists, each containing tensors representing an orthogonal direction.</p> Source code in <code>src/landscaper/utils.py</code> <pre><code>def generate_random_orthogonal_directions(model: torch.nn.Module, n: int = 3) -&gt; list[list[torch.Tensor]]:\n    \"\"\"Generates n random orthogonal directions in the parameter space of the model.\n\n    Args:\n        model (torch.nn.Module): The model for which to generate directions.\n        n (int, optional): Number of orthogonal directions to generate. Defaults to 3.\n\n    Returns:\n        list[list[torch.Tensor]]: A list of n lists, each containing tensors representing an orthogonal direction.\n    \"\"\"\n    directions = []\n    while len(directions) != n:\n        random_dir = [torch.randn_like(p.data) for p in model.parameters()]\n        for prev_dir in directions:\n            dot_product = sum((d1 * d2).sum() for d1, d2 in zip(random_dir, prev_dir, strict=False))\n\n            for j, (d1, d2) in enumerate(zip(random_dir, prev_dir, strict=False)):\n                random_dir[j] = d1 - dot_product * d2\n        directions.append(random_dir)\n    return directions\n</code></pre>"},{"location":"reference/landscaper/utils/#landscaper.utils.group_add","title":"<code>group_add(params, update, alpha=1)</code>","text":"<p>Adds the update to the parameters with a scaling factor alpha.</p> <p>Params = params + update*alpha</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>list[Tensor]</code> <p>List of parameters.</p> required <code>update</code> <code>list[Tensor]</code> <p>List of updates.</p> required <code>alpha</code> <code>float</code> <p>Scaling factor. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>list[Tensor]</code> <p>list[torch.Tensor]: Updated list of parameters.</p> Source code in <code>src/landscaper/utils.py</code> <pre><code>def group_add(params: list[torch.Tensor], update: list[torch.Tensor], alpha: float = 1) -&gt; list[torch.Tensor]:\n    \"\"\"Adds the update to the parameters with a scaling factor alpha.\n\n    Params = params + update*alpha\n\n    Args:\n        params (list[torch.Tensor]): List of parameters.\n        update (list[torch.Tensor]): List of updates.\n        alpha (float, optional): Scaling factor. Defaults to 1.\n\n    Returns:\n        list[torch.Tensor]: Updated list of parameters.\n    \"\"\"\n    for i, _ in enumerate(params):\n        params[i].data.add_(update[i] * alpha)\n    return params\n</code></pre>"},{"location":"reference/landscaper/utils/#landscaper.utils.group_product","title":"<code>group_product(xs, ys)</code>","text":"<p>Computes the dot product of two lists of tensors.</p> <p>Parameters:</p> Name Type Description Default <code>xs</code> <code>list[Tensor]</code> <p>List of tensors.</p> required <code>ys</code> <code>list[Tensor]</code> <p>List of tensors.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The sum of the element-wise products of the tensors in xs and ys.</p> Source code in <code>src/landscaper/utils.py</code> <pre><code>def group_product(xs: list[torch.Tensor], ys: list[torch.Tensor]) -&gt; torch.Tensor:\n    \"\"\"Computes the dot product of two lists of tensors.\n\n    Args:\n        xs (list[torch.Tensor]): List of tensors.\n        ys (list[torch.Tensor]): List of tensors.\n\n    Returns:\n        torch.Tensor: The sum of the element-wise products of the tensors in xs and ys.\n    \"\"\"\n    return sum([torch.sum(x * y) for (x, y) in zip(xs, ys, strict=False)])\n</code></pre>"},{"location":"reference/landscaper/utils/#landscaper.utils.load_landscape","title":"<code>load_landscape(fp)</code>","text":"<p>Loads a loss landscape from an .npz file.</p> <p>Parameters:</p> Name Type Description Default <code>fp</code> <code>str</code> <p>Path to the file.</p> required <p>Returns:</p> Name Type Description <code>Tuple</code> <code>(ArrayLike, ArrayLike)</code> <p>loss, coordinates.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Thrown if file is invalid.</p> Source code in <code>src/landscaper/utils.py</code> <pre><code>def load_landscape(fp: str) -&gt; tuple[npt.ArrayLike, npt.ArrayLike]:\n    \"\"\"Loads a loss landscape from an .npz file.\n\n    Args:\n        fp (str): Path to the file.\n\n    Returns:\n        Tuple(npt.ArrayLike, npt.ArrayLike): loss, coordinates.\n\n    Raises:\n        ValueError: Thrown if file is invalid.\n    \"\"\"\n    ext = os.path.splitext(fp)[1]\n    if ext != \".npz\":\n        raise ValueError(f\"File is not a .npz; got: {ext}\")\n\n    required = [\"loss\", \"coordinates\"]\n    d = np.load(fp)\n\n    if any([r not in d for r in required]):\n        raise ValueError(\"File is not a loss landscape.\")\n\n    loss = d.get(\"loss\")\n    coords = d.get(\"coordinates\")\n\n    dims = coords.shape[0]\n    if dims &lt; 2:\n        raise ValueError(\"Coordinates must at least be 2 dimensional.\")\n\n    return loss, coords\n</code></pre>"},{"location":"reference/landscaper/utils/#landscaper.utils.normalization","title":"<code>normalization(v)</code>","text":"<p>Normalization of a list of vectors v.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>list[Tensor]</code> <p>List of tensors to normalize.</p> required <p>Returns:</p> Type Description <code>list[Tensor]</code> <p>list[torch.Tensor]: Normalized list of tensors.</p> Source code in <code>src/landscaper/utils.py</code> <pre><code>def normalization(v: list[torch.Tensor]) -&gt; list[torch.Tensor]:\n    \"\"\"Normalization of a list of vectors v.\n\n    Args:\n        v (list[torch.Tensor]): List of tensors to normalize.\n\n    Returns:\n        list[torch.Tensor]: Normalized list of tensors.\n    \"\"\"\n    s = group_product(v, v)\n    s = s**0.5\n    s = s.cpu().item()\n    v = [vi / (s + 1e-6) for vi in v]\n    return v\n</code></pre>"},{"location":"reference/landscaper/utils/#landscaper.utils.orthnormal","title":"<code>orthnormal(w, v_list)</code>","text":"<p>Make vector w orthogonal to each vector in v_list and normalize the output w.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>list[Tensor]</code> <p>The vector to be made orthogonal.</p> required <code>v_list</code> <code>list[Tensor]</code> <p>List of vectors to which w should be made orthogonal.</p> required <p>Returns:</p> Type Description <code>list[Tensor]</code> <p>list[torch.Tensor]: The orthogonalized and normalized vector w.</p> Source code in <code>src/landscaper/utils.py</code> <pre><code>def orthnormal(w: list[torch.Tensor], v_list: list[torch.Tensor]) -&gt; list[torch.Tensor]:\n    \"\"\"Make vector w orthogonal to each vector in v_list and normalize the output w.\n\n    Args:\n        w (list[torch.Tensor]): The vector to be made orthogonal.\n        v_list (list[torch.Tensor]): List of vectors to which w should be made orthogonal.\n\n    Returns:\n        list[torch.Tensor]: The orthogonalized and normalized vector w.\n    \"\"\"\n    for v in v_list:\n        w = group_add(w, v, alpha=-group_product(w, v))\n    return normalization(w)\n</code></pre>"},{"location":"scripts/gen_ref_pages/","title":"Gen ref pages","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"Generate the code reference pages.\"\"\"\n</pre> \"\"\"Generate the code reference pages.\"\"\" In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n</pre> from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import mkdocs_gen_files\n</pre> import mkdocs_gen_files In\u00a0[\u00a0]: Copied! <pre>nav = mkdocs_gen_files.Nav()\n</pre> nav = mkdocs_gen_files.Nav() In\u00a0[\u00a0]: Copied! <pre>root = Path(__file__).parent.parent.parent\nsrc = root / \"src\"\n</pre> root = Path(__file__).parent.parent.parent src = root / \"src\" In\u00a0[\u00a0]: Copied! <pre>paths = list(sorted((src / \"landscaper\").rglob(\"*.py\")))\n</pre> paths = list(sorted((src / \"landscaper\").rglob(\"*.py\"))) In\u00a0[\u00a0]: Copied! <pre>for path in paths:\n    module_path = path.relative_to(src).with_suffix(\"\")\n\n    doc_path = path.relative_to(src).with_suffix(\".md\")\n\n    full_doc_path = Path(\"reference\", doc_path)\n\n    parts = tuple(module_path.parts)\n\n    if parts[-1] == \"__init__\":\n        parts = parts[:-1]\n        doc_path = doc_path.with_name(\"index.md\")\n        full_doc_path = full_doc_path.with_name(\"index.md\")\n    elif parts[-1] == \"main\":\n        continue\n\n    nav[parts] = doc_path.as_posix()\n\n    with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:\n        identifier = \".\".join(parts)\n        print(\"::: \" + identifier, file=fd)\n\n    mkdocs_gen_files.set_edit_path(full_doc_path, path.relative_to(root))\n</pre> for path in paths:     module_path = path.relative_to(src).with_suffix(\"\")      doc_path = path.relative_to(src).with_suffix(\".md\")      full_doc_path = Path(\"reference\", doc_path)      parts = tuple(module_path.parts)      if parts[-1] == \"__init__\":         parts = parts[:-1]         doc_path = doc_path.with_name(\"index.md\")         full_doc_path = full_doc_path.with_name(\"index.md\")     elif parts[-1] == \"main\":         continue      nav[parts] = doc_path.as_posix()      with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:         identifier = \".\".join(parts)         print(\"::: \" + identifier, file=fd)      mkdocs_gen_files.set_edit_path(full_doc_path, path.relative_to(root)) In\u00a0[\u00a0]: Copied! <pre>with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:\n    nav_file.writelines(nav.build_literate_nav())\n</pre> with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:     nav_file.writelines(nav.build_literate_nav())"}]}